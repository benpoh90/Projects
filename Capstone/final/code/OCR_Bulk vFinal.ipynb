{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b03d6f77",
   "metadata": {},
   "source": [
    "**Part 1**: OCR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99d2125",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cce7e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import math\n",
    "import argparse\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "import re, string, copy, os, glob\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import words\n",
    "from nltk.corpus import wordnet \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f973080f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arugment dictionary for default args \n",
    "args = {'input_folder':'../data/all_images/*.jpg', \n",
    "        'model':'../saved_models/east_text_detection.pb', \n",
    "        'thr':0.8, \n",
    "        'nms': 0.4, \n",
    "        'width_std':640, \n",
    "        'height_std':800,\n",
    "        'width_1':640,\n",
    "        'height_1': 640,\n",
    "        'padding':0.05,\n",
    "        'tesseract_conf': 70,\n",
    "        'tesseract_conf_lax': 40,\n",
    "        'padding_lax': 0.1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce51a5c3",
   "metadata": {},
   "source": [
    "# Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ebce84",
   "metadata": {},
   "source": [
    "There are two main goals for the project:\n",
    "* Part 1: Create a proof-of-concept for an optical character recognition (OCR) tool to capture text data from single-origin coffee bean packaging labels\n",
    "* Part 2: Deploy NLP techniques to accurately recommend coffees from a online store (sweetmarias.com) by leveraging the text data in the Part 1\n",
    "\n",
    "To narrow down the scope of the project, I will be focussing only on single origin coffee beans."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62093514",
   "metadata": {},
   "source": [
    "## Part 1: Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93cccee",
   "metadata": {},
   "source": [
    "This notebook will cover the OCR tool and the capturing of the data from this tool. While there are several ready-made OCR tools (ranging from open-source to paid APIs such as one offered by Amazon), the aim of this part is to create a tool which is free (i.e. using existing open-source models) and can suit the intended purpose (coffee labels). There are two main parts to creating this tool: **1) text detection** and **2) text recognition**. \n",
    "\n",
    "For text detection, I have chosen to use the EAST (Efficient and Accurate Scene Text) detector which is considered as one of the state-of-the-art deep learning architectures for text dectection. I have chosen to use EAST because it is trained on natural images and is fast (without compromising on accuracy) compared to other text detectors (e.g. YOLO).\n",
    "\n",
    "For text recognition, I have chosen to use Tesseract OCR. EAST is only a text detection architecture and only creates bounding boxes of text it identifies. Therefore, Tesseract will be deployed to 'recognise' the text in these bounding boxes and generate a best guess of what the text is. There are a few parameters that I have tuned to help improve the accuracy of the results from Tesseract - these will be explained further later.\n",
    "\n",
    "While the end product generates text using one image at a time, the code below is able to process multiple images. The rationale for doing this is to allow us to evaluate the results of over 300 different images and to optimise the text detection and recognition accuracy. This will then allow us to fine-tune our models to capture the needed information as accurately as possible. \n",
    "\n",
    "No OCR tool is perfect especially since they are an infinite permutations of how text will appear on images. The aim is to capture these 5 types of information (if available) as accurately as possible: **country, region, variety, processing method and tasting notes**.\n",
    "\n",
    "**Credit for images in dataset**:\n",
    "<br>\n",
    "IMG_0001 to IMG_0100 are from @gurucaleb on Instagram / IMG_0100 to IMG0300 are from Google search\n",
    "<br>\n",
    "All rights reserved to the copyright owners."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7610247b",
   "metadata": {},
   "source": [
    "# Text Detection - EAST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0dea00",
   "metadata": {},
   "source": [
    "## Resize Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddceba93",
   "metadata": {},
   "source": [
    "- EAST accepts images of W x H that are in multiples of 32\n",
    "- Most of the images are in potrait mode, we will therefore resize them to 800 x 640\n",
    "- For images that have W=H, we will resize them to 640 x 640 to avoid any compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4f775a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(image):\n",
    "    '''Function to resize images'''\n",
    "    \n",
    "    og_height = image.shape[0]\n",
    "    og_width = image.shape[1]\n",
    "    \n",
    "    if og_height == og_width:\n",
    "        resized_width = args['width_1']\n",
    "        resized_height = args['height_1']\n",
    "    else:\n",
    "        resized_width =  args['width_std']\n",
    "        resized_height = args['height_std']\n",
    "\n",
    "\n",
    "    resized_image= cv.resize(image, (resized_width, resized_height))\n",
    "        \n",
    "    return resized_image, (resized_width, resized_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312b594f",
   "metadata": {},
   "source": [
    "## Decode EAST output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faea394a",
   "metadata": {},
   "source": [
    "- Returns bounding boxe if probability score is above confidence threshold\n",
    "- Code adapted from OpenCV Github -> Samples -> dnn [[Source](https://github.com/opencv/opencv/tree/4.x/samples/dnn)]\n",
    "- FYI: code from EAST Github is mostly in C++ implementation [[Source](https://github.com/argman/EAST)], re-written into Python using guidance from the OpenCV codes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25b0f8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(scores, geometry, score_threshold):\n",
    "    '''Returns bounding boxes and probabilit scores if above confidence threshold'''\n",
    "    '''Code adapted from OpenCV Github -> Samples -> dnn'''\n",
    "    '''Code from EAST Github is mostly in C++ implementation'''\n",
    "    \n",
    "    detections = []\n",
    "    confidences = []\n",
    "\n",
    "    #Checks for incorrect dimensions\n",
    "    assert len(scores.shape) == 4, 'Incorrect dimensions of scores'\n",
    "    assert len(geometry.shape) == 4, 'Incorrect dimensions of geometry'\n",
    "    assert scores.shape[0] == 1, 'Invalid dimensions of scores'\n",
    "    assert geometry.shape[0] == 1, 'Invalid dimensions of geometry'\n",
    "    assert scores.shape[1] == 1, 'Invalid dimensions of scores'\n",
    "    assert geometry.shape[1] == 5, 'Invalid dimensions of geometry'\n",
    "    assert scores.shape[2] == geometry.shape[2], 'Invalid dimensions of scores and geometry'\n",
    "    assert scores.shape[3] == geometry.shape[3], 'Invalid dimensions of scores and geometry'\n",
    "    \n",
    "    height = scores.shape[2]\n",
    "    width = scores.shape[3]\n",
    "    \n",
    "    #Loop over rows\n",
    "    for y in range(0, height):\n",
    "\n",
    "        # Extract data from scores\n",
    "        scores_data = scores[0][0][y]\n",
    "        x0_data = geometry[0][0][y]\n",
    "        x1_data = geometry[0][1][y]\n",
    "        x2_data = geometry[0][2][y]\n",
    "        x3_data = geometry[0][3][y]\n",
    "        angles_data = geometry[0][4][y]\n",
    "        \n",
    "        #Loop over columns\n",
    "        for x in range(0, width):\n",
    "            score = scores_data[x]\n",
    "\n",
    "            # If score is lower than threshold score, ignore\n",
    "            if(score < score_threshold):\n",
    "                continue\n",
    "\n",
    "            #Multiply back to original dimnesions (EAST shrinks input by 4x)\n",
    "            offsetX = x * 4.0\n",
    "            offsetY = y * 4.0\n",
    "            angle = angles_data[x]\n",
    "\n",
    "            #Calculate cos and sin of angle\n",
    "            cosA = np.cos(angle)\n",
    "            sinA = np.sin(angle)\n",
    "            h = x0_data[x] + x2_data[x]\n",
    "            w = x1_data[x] + x3_data[x]\n",
    "\n",
    "            #Calculate offset\n",
    "            offset = ([offsetX + cosA * x1_data[x] + sinA * x2_data[x], offsetY - sinA * x1_data[x] + cosA * x2_data[x]])\n",
    "\n",
    "            #Find points for bounding box \n",
    "            #This also rotates bounding boxes to capture angled text\n",
    "            p1 = (-sinA * h + offset[0], -cosA * h + offset[1])\n",
    "            p3 = (-cosA * w + offset[0],  sinA * w + offset[1])\n",
    "            center = (0.5*(p1[0]+p3[0]), 0.5*(p1[1]+p3[1]))\n",
    "            detections.append((center, (w,h), -1*angle * 180.0 / np.pi))\n",
    "            confidences.append(float(score))\n",
    "\n",
    "    # Return detections and confidences\n",
    "    return [detections, confidences]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3637accd",
   "metadata": {},
   "source": [
    "## Run EAST Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b555fe",
   "metadata": {},
   "source": [
    "Parameters for EAST that I have adjusted:\n",
    "- Confidence threshold @ 80%\n",
    "- Non-maximum suppression threshold @ 40%\n",
    "\n",
    "The two outputs from EAST that we require are:\n",
    "- Probability scores of whether an area contains text or not\n",
    "- Coordinates of where the bounding box is detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68c7ea6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_detect():\n",
    "    \n",
    "    conf_threshold = args['thr']\n",
    "    nms_threshold = args['nms']\n",
    "    \n",
    "    # Load the pre-trained EAST model\n",
    "    model = args['model']\n",
    "    net = cv.dnn.readNet(model)\n",
    "\n",
    "    #Two outputs needed from the EAST model:\n",
    "    #1. Probability scores of whether an area contains text or not\n",
    "    #2. Coordinates of the bounding box when text is detected\n",
    "    outputNames = ['feature_fusion/Conv_7/Sigmoid', 'feature_fusion/concat_3']\n",
    "    \n",
    "    images = [file for file in glob.glob(args['input_folder'])]\n",
    "    images.sort() \n",
    "    images = [cv.imread(img) for img in images]\n",
    "    \n",
    "    indices_output = []\n",
    "    boxes_output = []\n",
    "    resized_output = []\n",
    "    for image in images:\n",
    "        resized, (resized_width, resized_height) = resize(image)\n",
    "        blob = cv.dnn.blobFromImage(resized, 1.0, (resized_width, resized_height), (123.68, 116.78, 103.94), True, False)\n",
    "        \n",
    "        net.setInput(blob)\n",
    "        output_detect = net.forward(outputNames)\n",
    "    \n",
    "        #Scores and geometry from model output (i.e. decode EAST output)\n",
    "        scores = output_detect[0]\n",
    "        geometry = output_detect[1]\n",
    "\n",
    "        [boxes, confidences] = decode(scores, geometry, conf_threshold)\n",
    "        \n",
    "        #Apply non-maximum suppression and return indices of bounding boxes\n",
    "        indices = cv.dnn.NMSBoxesRotated(boxes, confidences, conf_threshold, nms_threshold)\n",
    "        \n",
    "        indices_output.append(indices)\n",
    "        boxes_output.append(boxes)\n",
    "        resized_output.append(resized)\n",
    "        \n",
    "    yield indices_output\n",
    "    yield boxes_output\n",
    "    yield resized_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02a4a06",
   "metadata": {},
   "source": [
    "# Text Recognition - Tesseract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383c8bdb",
   "metadata": {},
   "source": [
    "Parameters for Tesseract that I have adjusted:\n",
    "- Confidence threshold @ 70%\n",
    "- Padding @ 5%\n",
    "- Lang = English\n",
    "- oem = 1 and psm = 6 (treat image as block of text)\n",
    "\n",
    "However, when less than 3 words are captured for an image, these parameters are re-adjusted:\n",
    "- Confidence threshold @ 40%\n",
    "- Padding @ 10%\n",
    "\n",
    "For text bounding boxes that are very small (i.e. <32 pixel in height), I have re-scaled them to 32 pixel because, according to this [author](https://groups.google.com/g/tesseract-ocr/c/Wdh_JJwnw94/m/24JHDYQbBQAJ), this is the 'ideal' font height for Tesseract to recognise text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eecc8d",
   "metadata": {},
   "source": [
    "## Run Tesseract Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b194840",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def gen_recognition():\n",
    "\n",
    "    conf_tesseract = args['tesseract_conf']\n",
    "    conf_tesseract_lax = args['tesseract_conf_lax']\n",
    "    padding = args['padding']\n",
    "    padding_lax = args['padding_lax']\n",
    "    \n",
    "    #Take bounding box coordinates/details from text detection part above\n",
    "    output_EAST = list(gen_detect())\n",
    "    indices_output = output_EAST[0]\n",
    "    boxes_output = output_EAST[1]\n",
    "    resized_output = output_EAST[2]\n",
    "\n",
    "    results = []\n",
    "    for img_id, (indices, boxes, image) in enumerate(zip(indices_output, boxes_output, resized_output)):\n",
    "        \n",
    "        sub_results = []\n",
    "        \n",
    "        for i in indices:\n",
    "            center = boxes[i[0]][0]\n",
    "            w, h = boxes[i[0]][1]\n",
    "            angle = boxes[i[0]][2]\n",
    "            \n",
    "            #Center of bounding boxes    \n",
    "            center_x, center_y = center\n",
    "            center_x = int(center_x)\n",
    "            center_y = int(center_y)\n",
    "\n",
    "            if w < h:\n",
    "                w, h = h, w\n",
    "                angle += 90.0\n",
    "\n",
    "            rows, cols, _ = image.shape\n",
    "\n",
    "            #Rotate bounding boxes that have angled text\n",
    "            matrix  = cv.getRotationMatrix2D(center, angle, 1)\n",
    "            rotated = cv.warpAffine(image, matrix, (cols, rows))\n",
    "\n",
    "            #padding\n",
    "            dX = int(w * padding)\n",
    "            dY = int(h * padding)\n",
    "\n",
    "            #Crop the rotated bounding box\n",
    "            start_y = int((center_y - (h / 2)) - dY)\n",
    "            end_y   = int((start_y + h) + (2 * dY))\n",
    "            start_x = int((center_x - (w / 2)) - dX)\n",
    "            end_x   = int((start_x + w) + (2 * dX))\n",
    "            start_x = start_x if 0 <= start_x < cols else (0 if start_x < 0 else cols-1)\n",
    "            end_x   = end_x if 0 <= end_x < cols else (0 if end_x < 0 else cols-1)\n",
    "            start_y = start_y if 0 <= start_y < rows else (0 if start_y < 0 else rows-1)\n",
    "            end_y   = end_y if 0 <= end_y < rows else (0 if end_y < 0 else rows-1)\n",
    "            crop    = rotated[start_y:end_y, start_x:end_x]\n",
    "\n",
    "            #Rescale very small bounding boxes to 32 height\n",
    "            if h < 32:\n",
    "                \n",
    "                crop = cv.resize(crop, None, fx=32/h, fy=32/h, interpolation=cv.INTER_CUBIC)\n",
    "                    \n",
    "            else:\n",
    "                crop\n",
    "\n",
    "            #Configuration setting to convert image to string\n",
    "            #Chosen english and spanish\n",
    "            configuration = ('-l eng+spa --oem 1 --psm 6')\n",
    "\n",
    "            #Recognize the text from the bounding box image \n",
    "            text = pytesseract.image_to_data(crop, config=configuration, output_type='data.frame')\n",
    "            selected_text = text.loc[(text['conf'] > conf_tesseract), ['conf','text']]\n",
    "            final_text = selected_text.values.tolist()\n",
    "\n",
    "            if not final_text:\n",
    "                continue\n",
    "                \n",
    "            if len(final_text) >= 2:\n",
    "                final_text = selected_text.loc[selected_text['conf'].idxmax(),:].values.tolist()\n",
    "            else:\n",
    "                final_text = final_text[0]\n",
    "            \n",
    "            max_conf = final_text[0]\n",
    "            \n",
    "            \n",
    "            max_text = str(final_text[1]).lower()\n",
    "            if re.search(r'[^\\w\\s]', max_text):\n",
    "                max_text = re.sub(r'[^\\w\\s]', '',max_text)\n",
    "                \n",
    "            if max_text == '':\n",
    "                continue\n",
    "            \n",
    "            sub_results.append((img_id+1, (start_x, start_y, end_x, end_y), max_conf, max_text))\n",
    "        \n",
    "        sub_results = sorted(sub_results, key=lambda x: x[1][1])\n",
    "        \n",
    "        #Re-run with less strict parameters if <3 words identified\n",
    "        if len(sub_results) > 3:\n",
    "            \n",
    "            results.append(sub_results)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            \n",
    "            sub_results_lax = []\n",
    "            for i in indices:\n",
    "                center = boxes[i[0]][0]\n",
    "                w, h = boxes[i[0]][1]\n",
    "                angle = boxes[i[0]][2]\n",
    "\n",
    "                #Center of bounding boxes    \n",
    "                center_x, center_y = center\n",
    "                center_x = int(center_x)\n",
    "                center_y = int(center_y)\n",
    "\n",
    "                if w < h:\n",
    "                    w, h = h, w\n",
    "                    angle += 90.0\n",
    "\n",
    "                rows, cols, _ = image.shape\n",
    "\n",
    "                #Rotate bounding boxes that have angled text\n",
    "                matrix  = cv.getRotationMatrix2D(center, angle, 1)\n",
    "                rotated = cv.warpAffine(image, matrix, (cols, rows))\n",
    "\n",
    "                #padding\n",
    "                dX = int(w * padding_lax)\n",
    "                dY = int(h * padding_lax)\n",
    "\n",
    "                #Crop the rotated bounding box\n",
    "                start_y = int((center_y - (h / 2)) - dY)\n",
    "                end_y   = int((start_y + h) + (2 * dY))\n",
    "                start_x = int((center_x - (w / 2)) - dX)\n",
    "                end_x   = int((start_x + w) + (2 * dX))\n",
    "                start_x = start_x if 0 <= start_x < cols else (0 if start_x < 0 else cols-1)\n",
    "                end_x   = end_x if 0 <= end_x < cols else (0 if end_x < 0 else cols-1)\n",
    "                start_y = start_y if 0 <= start_y < rows else (0 if start_y < 0 else rows-1)\n",
    "                end_y   = end_y if 0 <= end_y < rows else (0 if end_y < 0 else rows-1)\n",
    "                crop    = rotated[start_y:end_y, start_x:end_x]\n",
    "\n",
    "                #Rescale very small bounding boxes to 32 height\n",
    "                if h < 32:\n",
    "\n",
    "                    crop = cv.resize(crop, None, fx=32/h, fy=32/h, interpolation=cv.INTER_CUBIC)\n",
    "\n",
    "                else:\n",
    "                    crop\n",
    "\n",
    "                #Configuration setting to convert image to string\n",
    "                #Chosen english and spanish\n",
    "                configuration = ('-l eng --oem 1 --psm 6')\n",
    "\n",
    "                #Recognize the text from the bounding box image \n",
    "                text = pytesseract.image_to_data(crop, config=configuration, output_type='data.frame')\n",
    "                selected_text = text.loc[(text['conf'] > conf_tesseract_lax), ['conf','text']]\n",
    "                final_text = selected_text.values.tolist()\n",
    "\n",
    "                if not final_text:\n",
    "                    continue\n",
    "\n",
    "                if len(final_text) >= 2:\n",
    "                    final_text = selected_text.loc[selected_text['conf'].idxmax(),:].values.tolist()\n",
    "                else:\n",
    "                    final_text = final_text[0]\n",
    "\n",
    "                max_conf = final_text[0]\n",
    "\n",
    "\n",
    "                max_text = str(final_text[1]).lower()\n",
    "                if re.search(r'[^a-zA-Z]', max_text):\n",
    "                    max_text = re.sub(r'[^a-zA-Z]', '',max_text)\n",
    "                \n",
    "                if max_text == '' or max_text == ' ':\n",
    "                    continue\n",
    "                \n",
    "                sub_results_lax.append((img_id+1, (start_x, start_y, end_x, end_y), max_conf, max_text))\n",
    "                \n",
    "            sub_results_lax = sorted(sub_results_lax, key=lambda x: x[1][0])\n",
    "            results.append(sub_results_lax)\n",
    "    yield results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779eb151",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8489ef9b",
   "metadata": {},
   "source": [
    "The results of all 303 images are captured below. For Part 2, I have compiled them into 303 rows with all text captured recorded under the 'text' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c233a01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Run generator\n",
    "results = list(gen_recognition())\n",
    "\n",
    "#Update results into dataframe\n",
    "image_data = [x for x in results[0]]\n",
    "df_results = []\n",
    "for data in image_data:\n",
    "    data_results = pd.DataFrame(data, columns=['img_id','bbox coord', 'conf', 'text'])\n",
    "    df_results.append(data_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ee52ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_id</th>\n",
       "      <th>bbox coord</th>\n",
       "      <th>conf</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>(274, 166, 350, 191)</td>\n",
       "      <td>92.0</td>\n",
       "      <td>elegant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>(454, 166, 493, 188)</td>\n",
       "      <td>86.0</td>\n",
       "      <td>yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>(191, 181, 238, 208)</td>\n",
       "      <td>86.0</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>(411, 199, 457, 221)</td>\n",
       "      <td>95.0</td>\n",
       "      <td>very</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>(196, 206, 244, 232)</td>\n",
       "      <td>94.0</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>303</td>\n",
       "      <td>(207, 629, 305, 643)</td>\n",
       "      <td>85.0</td>\n",
       "      <td>producer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>303</td>\n",
       "      <td>(301, 635, 389, 650)</td>\n",
       "      <td>89.0</td>\n",
       "      <td>fernando</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>303</td>\n",
       "      <td>(339, 653, 414, 668)</td>\n",
       "      <td>83.0</td>\n",
       "      <td>process</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>303</td>\n",
       "      <td>(411, 656, 474, 671)</td>\n",
       "      <td>96.0</td>\n",
       "      <td>washed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>303</td>\n",
       "      <td>(287, 771, 333, 786)</td>\n",
       "      <td>81.0</td>\n",
       "      <td>25090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4123 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   img_id            bbox coord  conf      text\n",
       "0       1  (274, 166, 350, 191)  92.0   elegant\n",
       "1       1  (454, 166, 493, 188)  86.0       yet\n",
       "2       1  (191, 181, 238, 208)  86.0       med\n",
       "3       1  (411, 199, 457, 221)  95.0      very\n",
       "4       1  (196, 206, 244, 232)  94.0       med\n",
       "..    ...                   ...   ...       ...\n",
       "8     303  (207, 629, 305, 643)  85.0  producer\n",
       "9     303  (301, 635, 389, 650)  89.0  fernando\n",
       "10    303  (339, 653, 414, 668)  83.0   process\n",
       "11    303  (411, 656, 474, 671)  96.0    washed\n",
       "12    303  (287, 771, 333, 786)  81.0     25090\n",
       "\n",
       "[4123 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Summary of results    \n",
    "summary = pd.concat(df_results)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60efa1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export summary to CSV\n",
    "\n",
    "summary.to_csv(r'../data/summary_all_images_70pct_0811_vfinal.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68927978",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a60478",
   "metadata": {},
   "source": [
    "### Drop NaNs and Blank Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0250e1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace any remaining blanks with nan and drop the row.\n",
    "\n",
    "summary['text'].replace('', np.nan, inplace=True)\n",
    "summary['text'].replace(' ', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a5211ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.dropna(subset=['text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5da2d405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_id</th>\n",
       "      <th>bbox coord</th>\n",
       "      <th>conf</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>(274, 166, 350, 191)</td>\n",
       "      <td>92.0</td>\n",
       "      <td>elegant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>(454, 166, 493, 188)</td>\n",
       "      <td>86.0</td>\n",
       "      <td>yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>(191, 181, 238, 208)</td>\n",
       "      <td>86.0</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>(411, 199, 457, 221)</td>\n",
       "      <td>95.0</td>\n",
       "      <td>very</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>(196, 206, 244, 232)</td>\n",
       "      <td>94.0</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>303</td>\n",
       "      <td>(207, 629, 305, 643)</td>\n",
       "      <td>85.0</td>\n",
       "      <td>producer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>303</td>\n",
       "      <td>(301, 635, 389, 650)</td>\n",
       "      <td>89.0</td>\n",
       "      <td>fernando</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>303</td>\n",
       "      <td>(339, 653, 414, 668)</td>\n",
       "      <td>83.0</td>\n",
       "      <td>process</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>303</td>\n",
       "      <td>(411, 656, 474, 671)</td>\n",
       "      <td>96.0</td>\n",
       "      <td>washed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>303</td>\n",
       "      <td>(287, 771, 333, 786)</td>\n",
       "      <td>81.0</td>\n",
       "      <td>25090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4123 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   img_id            bbox coord  conf      text\n",
       "0       1  (274, 166, 350, 191)  92.0   elegant\n",
       "1       1  (454, 166, 493, 188)  86.0       yet\n",
       "2       1  (191, 181, 238, 208)  86.0       med\n",
       "3       1  (411, 199, 457, 221)  95.0      very\n",
       "4       1  (196, 206, 244, 232)  94.0       med\n",
       "..    ...                   ...   ...       ...\n",
       "8     303  (207, 629, 305, 643)  85.0  producer\n",
       "9     303  (301, 635, 389, 650)  89.0  fernando\n",
       "10    303  (339, 653, 414, 668)  83.0   process\n",
       "11    303  (411, 656, 474, 671)  96.0    washed\n",
       "12    303  (287, 771, 333, 786)  81.0     25090\n",
       "\n",
       "[4123 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dc265a",
   "metadata": {},
   "source": [
    "### Remove non-words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a8cc30",
   "metadata": {},
   "source": [
    "In order for the recommender system to work effectively in part 2, we need to pass in words that make sense. In the steps below, I have cleaned the input from the OCR tool by performing basic lemmatisation and removing words that are no found in the wordnet dictionary. However, to account for some unique words such as bean variety (e.g. 'caturra', 'catuai'), I have manually added them into the dictionary to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ffcb1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manually adding words related to bean variety/regions\n",
    "\n",
    "manual_additions_words = ['caturra', 'catuai', 'gesha', 'bourbon', 'arabica', 'sidama', 'sidamo', 'yirgacheffe', 'harrar', 'limu', 'guji']\n",
    "nltk_words = set.union(set(nltk.corpus.wordnet.words()),set(nltk.corpus.words.words()))\n",
    "\n",
    "total_words = nltk_words.union(manual_additions_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b3f25a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(row):\n",
    "    '''Function to apply basic cleaning and lemmaitization'''\n",
    "    \n",
    "    #remove all non-alphabet characters\n",
    "    row['text'] = re.sub(r'[^a-zA-Z]',' ', row['text']) \n",
    "    \n",
    "    #lemmatize words to check if they exist\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lem_word = lemmatizer.lemmatize(row['text'])\n",
    "    row['cleaned_text'] = lem_word\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a33dcabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(row):\n",
    "    '''Utility function to check if text to remove is valid'''\n",
    "    \n",
    "    if row['cleaned_text'] in total_words:\n",
    "        row['check'] = 'Yes'\n",
    "    else:\n",
    "        row['check'] = 'No'\n",
    "        \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a95e1a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summary.apply(clean_text, axis=1).apply(check, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd0ba5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_id</th>\n",
       "      <th>bbox coord</th>\n",
       "      <th>conf</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>(274, 166, 350, 191)</td>\n",
       "      <td>92.0</td>\n",
       "      <td>elegant</td>\n",
       "      <td>elegant</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>(454, 166, 493, 188)</td>\n",
       "      <td>86.0</td>\n",
       "      <td>yet</td>\n",
       "      <td>yet</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>(191, 181, 238, 208)</td>\n",
       "      <td>86.0</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>(411, 199, 457, 221)</td>\n",
       "      <td>95.0</td>\n",
       "      <td>very</td>\n",
       "      <td>very</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>(196, 206, 244, 232)</td>\n",
       "      <td>94.0</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>303</td>\n",
       "      <td>(207, 629, 305, 643)</td>\n",
       "      <td>85.0</td>\n",
       "      <td>producer</td>\n",
       "      <td>producer</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>303</td>\n",
       "      <td>(301, 635, 389, 650)</td>\n",
       "      <td>89.0</td>\n",
       "      <td>fernando</td>\n",
       "      <td>fernando</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>303</td>\n",
       "      <td>(339, 653, 414, 668)</td>\n",
       "      <td>83.0</td>\n",
       "      <td>process</td>\n",
       "      <td>process</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>303</td>\n",
       "      <td>(411, 656, 474, 671)</td>\n",
       "      <td>96.0</td>\n",
       "      <td>washed</td>\n",
       "      <td>washed</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>303</td>\n",
       "      <td>(287, 771, 333, 786)</td>\n",
       "      <td>81.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4123 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    img_id            bbox coord  conf      text cleaned_text check\n",
       "0        1  (274, 166, 350, 191)  92.0   elegant      elegant   Yes\n",
       "1        1  (454, 166, 493, 188)  86.0       yet          yet   Yes\n",
       "2        1  (191, 181, 238, 208)  86.0       med          med   Yes\n",
       "3        1  (411, 199, 457, 221)  95.0      very         very   Yes\n",
       "4        1  (196, 206, 244, 232)  94.0       med          med   Yes\n",
       "..     ...                   ...   ...       ...          ...   ...\n",
       "8      303  (207, 629, 305, 643)  85.0  producer     producer   Yes\n",
       "9      303  (301, 635, 389, 650)  89.0  fernando     fernando    No\n",
       "10     303  (339, 653, 414, 668)  83.0   process      process   Yes\n",
       "11     303  (411, 656, 474, 671)  96.0    washed       washed   Yes\n",
       "12     303  (287, 771, 333, 786)  81.0                           No\n",
       "\n",
       "[4123 rows x 6 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c21025d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove non-words (i.e. those marked as 'No')\n",
    "\n",
    "summary = summary[summary['check'] == 'Yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71634097",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove words <3 characters\n",
    "\n",
    "summary = summary.loc[summary['cleaned_text'].str.len() >=3 ,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aba13f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_id</th>\n",
       "      <th>bbox coord</th>\n",
       "      <th>conf</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>(274, 166, 350, 191)</td>\n",
       "      <td>92.0</td>\n",
       "      <td>elegant</td>\n",
       "      <td>elegant</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>(454, 166, 493, 188)</td>\n",
       "      <td>86.0</td>\n",
       "      <td>yet</td>\n",
       "      <td>yet</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>(191, 181, 238, 208)</td>\n",
       "      <td>86.0</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>(411, 199, 457, 221)</td>\n",
       "      <td>95.0</td>\n",
       "      <td>very</td>\n",
       "      <td>very</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>(196, 206, 244, 232)</td>\n",
       "      <td>94.0</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>303</td>\n",
       "      <td>(314, 600, 364, 613)</td>\n",
       "      <td>95.0</td>\n",
       "      <td>green</td>\n",
       "      <td>green</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>303</td>\n",
       "      <td>(423, 602, 493, 616)</td>\n",
       "      <td>95.0</td>\n",
       "      <td>almond</td>\n",
       "      <td>almond</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>303</td>\n",
       "      <td>(207, 629, 305, 643)</td>\n",
       "      <td>85.0</td>\n",
       "      <td>producer</td>\n",
       "      <td>producer</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>303</td>\n",
       "      <td>(339, 653, 414, 668)</td>\n",
       "      <td>83.0</td>\n",
       "      <td>process</td>\n",
       "      <td>process</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>303</td>\n",
       "      <td>(411, 656, 474, 671)</td>\n",
       "      <td>96.0</td>\n",
       "      <td>washed</td>\n",
       "      <td>washed</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2552 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    img_id            bbox coord  conf      text cleaned_text check\n",
       "0        1  (274, 166, 350, 191)  92.0   elegant      elegant   Yes\n",
       "1        1  (454, 166, 493, 188)  86.0       yet          yet   Yes\n",
       "2        1  (191, 181, 238, 208)  86.0       med          med   Yes\n",
       "3        1  (411, 199, 457, 221)  95.0      very         very   Yes\n",
       "4        1  (196, 206, 244, 232)  94.0       med          med   Yes\n",
       "..     ...                   ...   ...       ...          ...   ...\n",
       "6      303  (314, 600, 364, 613)  95.0     green        green   Yes\n",
       "7      303  (423, 602, 493, 616)  95.0    almond       almond   Yes\n",
       "8      303  (207, 629, 305, 643)  85.0  producer     producer   Yes\n",
       "10     303  (339, 653, 414, 668)  83.0   process      process   Yes\n",
       "11     303  (411, 656, 474, 671)  96.0    washed       washed   Yes\n",
       "\n",
       "[2552 rows x 6 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa256e5",
   "metadata": {},
   "source": [
    "### New DataFrame - Consolidate text by image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3bfa5f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_consolidated = summary.groupby('img_id')['cleaned_text'].apply(lambda x: \"%s\" % ', '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "865e8ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_consolidated = pd.DataFrame(summary_consolidated, columns=['cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "924bc60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_consolidated.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f04d254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_list(string):\n",
    "    ulist = []\n",
    "    [ulist.append(x) for x in string if x not in ulist]\n",
    "    return ulist\n",
    "\n",
    "def dupe(row):\n",
    "    split = row['cleaned_text'].split(', ')\n",
    "    row['final_text'] = ', '.join(unique_list(split))\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a76a529",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_consolidated = summary_consolidated.apply(dupe, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f90374a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_consolidated.drop(columns='cleaned_text', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c324f9b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_id</th>\n",
       "      <th>final_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>elegant, yet, med, very, body, clean, brightne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ethiopia, balance, indigenous, heirloom, dried...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>kenya, bellingham, roasted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ethiopia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>coffee, whole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>299</td>\n",
       "      <td>gram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>300</td>\n",
       "      <td>coffee, world, old, natural, costa, don, juicy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>301</td>\n",
       "      <td>method, natural, processing, mixed, lao, altit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>302</td>\n",
       "      <td>black, harvest, elevation, shan, state, myanma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>303</td>\n",
       "      <td>colombia, vanilla, green, almond, producer, pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     img_id                                         final_text\n",
       "0         1  elegant, yet, med, very, body, clean, brightne...\n",
       "1         2  ethiopia, balance, indigenous, heirloom, dried...\n",
       "2         3                         kenya, bellingham, roasted\n",
       "3         4                                           ethiopia\n",
       "4         5                                      coffee, whole\n",
       "..      ...                                                ...\n",
       "295     299                                               gram\n",
       "296     300  coffee, world, old, natural, costa, don, juicy...\n",
       "297     301  method, natural, processing, mixed, lao, altit...\n",
       "298     302  black, harvest, elevation, shan, state, myanma...\n",
       "299     303  colombia, vanilla, green, almond, producer, pr...\n",
       "\n",
       "[300 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_consolidated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604c8658",
   "metadata": {},
   "source": [
    "## Basic EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee3d01f",
   "metadata": {},
   "source": [
    "Not surprising, words like 'coffee', 'process', 'roasters' appear most frequently. 'Useful' words such as 'Ethiopia', 'natural', 'chocolate' are also captured quite a few times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb2fefb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_id</th>\n",
       "      <th>bbox coord</th>\n",
       "      <th>conf</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>check</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coffee</th>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>process</th>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roasters</th>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>washed</th>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ethiopia</th>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roasted</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>natural</th>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>notes</th>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>net</th>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chocolate</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>red</th>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whole</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roast</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           img_id  bbox coord  conf  cleaned_text  check\n",
       "text                                                    \n",
       "coffee        125         125   125           125    125\n",
       "process        58          58    58            58     58\n",
       "roasters       55          55    55            55     55\n",
       "washed         53          53    53            53     53\n",
       "ethiopia       40          40    40            40     40\n",
       "roasted        39          39    39            39     39\n",
       "the            35          35    35            35     35\n",
       "natural        35          35    35            35     35\n",
       "and            32          32    32            32     32\n",
       "notes          31          31    31            31     31\n",
       "net            30          30    30            30     30\n",
       "chocolate      29          29    29            29     29\n",
       "red            28          28    28            28     28\n",
       "whole          27          27    27            27     27\n",
       "roast          26          26    26            26     26"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.groupby('text').count().sort_values(by='conf',ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36f44d1",
   "metadata": {},
   "source": [
    "**Average Number of Words Per Capture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "74530e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 words\n"
     ]
    }
   ],
   "source": [
    "doc_length = []\n",
    "for document in range(len(summary_consolidated['final_text'])):\n",
    "    doc_length.append(len(summary_consolidated['final_text'][document].split(', ')))\n",
    "\n",
    "avg_doc_length = sum(doc_length)/len(doc_length)\n",
    "print(f'{round(avg_doc_length)}' + ' words')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e918d09",
   "metadata": {},
   "source": [
    "## Consolidate results and export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4e853a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_consolidated.to_csv(r'..data/consolidated_all_images_70pct_0811_vfinal.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196d84bb",
   "metadata": {},
   "source": [
    "# Acknowlegments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a29230",
   "metadata": {},
   "source": [
    "These are the resources which I have found helpful:\n",
    "\n",
    "[EAST Github](https://github.com/argman/EAST)\n",
    "<br>\n",
    "[OpenCV Github (for implementation of EAST in Python)](https://github.com/opencv/opencv/tree/4.x/samples/dnn)\n",
    "<br>\n",
    "\n",
    "Other Resources:\n",
    "<br>\n",
    "https://www.pyimagesearch.com/2018/08/20/opencv-text-detection-east-text-detector/?_ga=2.123146509.781830900.1634551481-1925401864.1633847684\n",
    "<br>\n",
    "https://nanonets.com/blog/ocr-with-tesseract/\n",
    "<br>\n",
    "https://www.pyimagesearch.com/2018/09/17/opencv-ocr-and-text-recognition-with-tesseract/\n",
    "<br>\n",
    "https://nanonets.com/blog/deep-learning-ocr/#text-detection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "243px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
