{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f99d2125",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3cce7e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import math\n",
    "import argparse\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "import re, string, copy, os, glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f973080f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arugment dictionary for default args \n",
    "args = {'input_folder':'../test/all_images/*.jpg', \n",
    "        'model':'../test/east_text_detection.pb', \n",
    "        'thr':0.8, \n",
    "        'nms': 0.4, \n",
    "        'width_std':640, \n",
    "        'height_std':800,\n",
    "        'width_1':640,\n",
    "        'height_1': 640,\n",
    "        'padding':0.05,\n",
    "        'tesseract_conf': 70,\n",
    "        'tesseract_conf_lax': 40,\n",
    "        'padding_lax': 0.1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce51a5c3",
   "metadata": {},
   "source": [
    "# Brief Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ebce84",
   "metadata": {},
   "source": [
    "There are two main goals for the project:\n",
    "* Part 1: Create an optical character recognition (OCR) tool to capture text data from coffee bean packaging labels\n",
    "* Part 2: Deploy NLP techniques to recommend coffees from a online store (sweetmarias.com) by leveraging the text data in the Part 1\n",
    "\n",
    "To narrow down the scope of the project, I will be focussing only on single origin coffee beans."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62093514",
   "metadata": {},
   "source": [
    "## Part 1: Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93cccee",
   "metadata": {},
   "source": [
    "This notebook will cover the OCR tool and the capturing of the data from this tool. While there are several ready-made OCR tools (ranging from open-source to paid APIs such as one offered by Amazon), the aim of this part is to create a tool which is free (i.e. using existing open-source models) and can suit the intended purpose (coffee labels). There are two main parts to creating this tool: **1) text detection** and **2) text recognition**. \n",
    "\n",
    "For text detection, I have chosen to use the EAST (Efficient and Accurate Scene Text) detector which is considered as one of the state-of-the-art deep learning architectures for text dectection. I have chosen to use EAST because it is trained on natural images and is fast (without compromising on accuracy) compared to other text detectors (e.g. YOLO).\n",
    "\n",
    "For text recognition, I have chosen to use Tesseract OCR. EAST is only a text detection architecture and only creates bounding boxes of text it identifies. Therefore, Tesseract will be deployed to 'recognise' the text in these bounding boxes and generate it's best guess of what the text is. There are a few parameters that I have tuned to help improve the accuracy of the results from Tesseract - these will be explained further later.\n",
    "\n",
    "While the end product generates text using one image at a time, the code below is able to process multiple images. The rationale for doing this is to allow us to evaluate the results of over 300 different images and to optimise the text detection and recognition accuracy. This will then allow us to fine-tune our models to capture the needed information as accurately as possible. \n",
    "\n",
    "No OCR tool is perfect especially since they are an infinite permutations of how text will appear on images. The aim is to capture these 5 types of information (if available) as accurately as possible: **country, region, variety, processing method and tasting notes**.\n",
    "\n",
    "There are a few challenges faced while working on this text detector:\n",
    "- Angled text - EAST is in C++ implementation, had to adapt code from OpenCV's architecture\n",
    "- 300 images sourced from internet, all of different sizes/quality - manually pre-process them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7610247b",
   "metadata": {},
   "source": [
    "# Text Detection - EAST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0dea00",
   "metadata": {},
   "source": [
    "## Resize Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4f775a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(image):\n",
    "    '''EAST accepts images of W x H that are in multiples of 32'''\n",
    "    '''Most of the images are in potrait mode, we will resize them to 800 x 640'''\n",
    "    '''For images that have W=H, we will resize them to 640 x 640 to avoid any compression'''\n",
    "    \n",
    "    og_height = image.shape[0]\n",
    "    og_width = image.shape[1]\n",
    "\n",
    "    #rW = og_width / float(resized_width)\n",
    "    #rH = og_height / float(resized_height)\n",
    "    \n",
    "    if og_height == og_width:\n",
    "        resized_width = args['width_1']\n",
    "        resized_height = args['height_1']\n",
    "    else:\n",
    "        resized_width =  args['width_std']\n",
    "        resized_height = args['height_std']\n",
    "\n",
    "\n",
    "    resized_image= cv.resize(image, (resized_width, resized_height))\n",
    "        \n",
    "    return resized_image, (resized_width, resized_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312b594f",
   "metadata": {},
   "source": [
    "## Function to decode EAST output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "25b0f8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(scores, geometry, scoreThresh):\n",
    "    '''Returns bounding boxes and probabilit scores if above confidence threshold'''\n",
    "    '''Code adapted from OpenCV Github -> Samples -> dnn'''\n",
    "    '''Code from EAST Github is mostly in C++ implementation'''\n",
    "    \n",
    "    detections = []\n",
    "    confidences = []\n",
    "\n",
    "    #Checks for incorrect dimensions\n",
    "    assert len(scores.shape) == 4, \"Incorrect dimensions of scores\"\n",
    "    assert len(geometry.shape) == 4, \"Incorrect dimensions of geometry\"\n",
    "    assert scores.shape[0] == 1, \"Invalid dimensions of scores\"\n",
    "    assert geometry.shape[0] == 1, \"Invalid dimensions of geometry\"\n",
    "    assert scores.shape[1] == 1, \"Invalid dimensions of scores\"\n",
    "    assert geometry.shape[1] == 5, \"Invalid dimensions of geometry\"\n",
    "    assert scores.shape[2] == geometry.shape[2], \"Invalid dimensions of scores and geometry\"\n",
    "    assert scores.shape[3] == geometry.shape[3], \"Invalid dimensions of scores and geometry\"\n",
    "    \n",
    "    height = scores.shape[2]\n",
    "    width = scores.shape[3]\n",
    "    \n",
    "    #Loop over rows\n",
    "    for y in range(0, height):\n",
    "\n",
    "        # Extract data from scores\n",
    "        scoresData = scores[0][0][y]\n",
    "        x0_data = geometry[0][0][y]\n",
    "        x1_data = geometry[0][1][y]\n",
    "        x2_data = geometry[0][2][y]\n",
    "        x3_data = geometry[0][3][y]\n",
    "        anglesData = geometry[0][4][y]\n",
    "        \n",
    "        #Loop over columns\n",
    "        for x in range(0, width):\n",
    "            score = scoresData[x]\n",
    "\n",
    "            # If score is lower than threshold score, move to next x\n",
    "            if(score < scoreThresh):\n",
    "                continue\n",
    "\n",
    "            #Multiply back to original dimnesions (EAST shrinks input by 4x)\n",
    "            offsetX = x * 4.0\n",
    "            offsetY = y * 4.0\n",
    "            angle = anglesData[x]\n",
    "\n",
    "            #Calculate cos and sin of angle\n",
    "            cosA = np.cos(angle)\n",
    "            sinA = np.sin(angle)\n",
    "            h = x0_data[x] + x2_data[x]\n",
    "            w = x1_data[x] + x3_data[x]\n",
    "\n",
    "            #Calculate offset\n",
    "            offset = ([offsetX + cosA * x1_data[x] + sinA * x2_data[x], offsetY - sinA * x1_data[x] + cosA * x2_data[x]])\n",
    "\n",
    "            #Find points for bounding box \n",
    "            #This rotates bounding boxes for angled text as well\n",
    "            p1 = (-sinA * h + offset[0], -cosA * h + offset[1])\n",
    "            p3 = (-cosA * w + offset[0],  sinA * w + offset[1])\n",
    "            center = (0.5*(p1[0]+p3[0]), 0.5*(p1[1]+p3[1]))\n",
    "            detections.append((center, (w,h), -1*angle * 180.0 / np.pi))\n",
    "            confidences.append(float(score))\n",
    "\n",
    "    # Return detections and confidences\n",
    "    return [detections, confidences]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3637accd",
   "metadata": {},
   "source": [
    "## Run EAST Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b555fe",
   "metadata": {},
   "source": [
    "Parameters for EAST that I have adjusted:\n",
    "- Confidence threshold @ 80%\n",
    "- Non-maximum suppression threshold @ 40%\n",
    "\n",
    "The two outputs from EAST that we require are:\n",
    "- Probability scores of whether an area contains text or not\n",
    "- Coordinates of where the bounding box is detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "68c7ea6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_detect():\n",
    "    \n",
    "    confThreshold = args['thr']\n",
    "    nmsThreshold = args['nms']\n",
    "    \n",
    "    # Load the pre-trained EAST model\n",
    "    model = args['model']\n",
    "    net = cv.dnn.readNet(model)\n",
    "\n",
    "    #Two outputs needed from the EAST model:\n",
    "    #1. Probability scores of whether an area contains text or not\n",
    "    #2. Coordinates of the bounding box when text is detected\n",
    "    outputNames = ['feature_fusion/Conv_7/Sigmoid', 'feature_fusion/concat_3']\n",
    "    \n",
    "    images = [file for file in glob.glob(args['input_folder'])]\n",
    "    images.sort() \n",
    "    images = [cv.imread(img) for img in images]\n",
    "    \n",
    "    indices_output = []\n",
    "    boxes_output = []\n",
    "    resized_output = []\n",
    "    for image in images:\n",
    "        resized, (resized_width, resized_height) = resize(image)\n",
    "        blob = cv.dnn.blobFromImage(resized, 1.0, (resized_width, resized_height), (123.68, 116.78, 103.94), True, False)\n",
    "        \n",
    "        net.setInput(blob)\n",
    "        output_detect = net.forward(outputNames)\n",
    "    \n",
    "        #Scores and geometry from model output\n",
    "        scores = output_detect[0]\n",
    "        geometry = output_detect[1]\n",
    "\n",
    "        [boxes, confidences] = decode(scores, geometry, confThreshold)\n",
    "        \n",
    "        #Apply non-maximum suppression and return indices of bounding boxes\n",
    "        indices = cv.dnn.NMSBoxesRotated(boxes, confidences, confThreshold,nmsThreshold)\n",
    "        \n",
    "        indices_output.append(indices)\n",
    "        boxes_output.append(boxes)\n",
    "        resized_output.append(resized)\n",
    "        \n",
    "    yield indices_output\n",
    "    yield boxes_output\n",
    "    yield resized_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02a4a06",
   "metadata": {},
   "source": [
    "# Text Recognition - Tesseract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383c8bdb",
   "metadata": {},
   "source": [
    "Parameters for Tesseract that I have adjusted:\n",
    "- Confidence threshold @ 70%\n",
    "- Padding @ 5%\n",
    "- Lang = English and Spanish\n",
    "- oem = 1 and psm = 6\n",
    "\n",
    "However, when less than 3 words are captured for an image, these parameters are re-adjusted:\n",
    "- Confidence threshold @ 40%\n",
    "- Padding @ 10%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eecc8d",
   "metadata": {},
   "source": [
    "## Run Tesseract Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b194840",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def gen_recognition():\n",
    "\n",
    "    confTesseract = args['tesseract_conf']\n",
    "    confTesseract_lax = args['tesseract_conf_lax']\n",
    "    padding = args['padding']\n",
    "    padding_lax = args['padding_lax']\n",
    "    \n",
    "    \n",
    "    output_EAST = list(gen_detect())\n",
    "    indices_output = output_EAST[0]\n",
    "    boxes_output = output_EAST[1]\n",
    "    resized_output = output_EAST[2]\n",
    "\n",
    "    results = []\n",
    "    for img_id, (indices, boxes, image) in enumerate(zip(indices_output, boxes_output, resized_output)):\n",
    "        \n",
    "        sub_results = []\n",
    "        \n",
    "        for i in indices:\n",
    "            center = boxes[i[0]][0]\n",
    "            w, h = boxes[i[0]][1]\n",
    "            angle = boxes[i[0]][2]\n",
    "            \n",
    "            #Center of bounding boxes    \n",
    "            center_x, center_y = center\n",
    "            center_x = int(center_x)\n",
    "            center_y = int(center_y)\n",
    "\n",
    "            if w < h:\n",
    "                w, h = h, w\n",
    "                angle += 90.0\n",
    "\n",
    "            rows, cols, _ = image.shape\n",
    "\n",
    "            #Rotate bounding boxes that have angled text\n",
    "            matrix  = cv.getRotationMatrix2D(center, angle, 1)\n",
    "            rotated = cv.warpAffine(image, matrix, (cols, rows))\n",
    "\n",
    "            #padding\n",
    "            dX = int(w * padding)\n",
    "            dY = int(h * padding)\n",
    "\n",
    "            #Crop the rotated bounding box\n",
    "            start_y = int((center_y - (h / 2)) - dY)\n",
    "            end_y   = int((start_y + h) + (2 * dY))\n",
    "            start_x = int((center_x - (w / 2)) - dX)\n",
    "            end_x   = int((start_x + w) + (2 * dX))\n",
    "            start_x = start_x if 0 <= start_x < cols else (0 if start_x < 0 else cols-1)\n",
    "            end_x   = end_x if 0 <= end_x < cols else (0 if end_x < 0 else cols-1)\n",
    "            start_y = start_y if 0 <= start_y < rows else (0 if start_y < 0 else rows-1)\n",
    "            end_y   = end_y if 0 <= end_y < rows else (0 if end_y < 0 else rows-1)\n",
    "            crop    = rotated[start_y:end_y, start_x:end_x]\n",
    "\n",
    "            #Rescale very small bounding boxes to 32 height\n",
    "            if h < 32:\n",
    "                \n",
    "                crop = cv.resize(crop, None, fx=32/h, fy=32/h, interpolation=cv.INTER_CUBIC)\n",
    "                    \n",
    "            else:\n",
    "                crop\n",
    "\n",
    "            #Configuration setting to convert image to string\n",
    "            #Chosen english and spanish\n",
    "            configuration = ('-l eng+spa --oem 1 --psm 6')\n",
    "\n",
    "            #Recognize the text from the bounding box image \n",
    "            text = pytesseract.image_to_data(crop, config=configuration, output_type='data.frame')\n",
    "            selected_text = text.loc[(text['conf'] > confTesseract), ['conf','text']]\n",
    "            final_text = selected_text.values.tolist()\n",
    "\n",
    "            if not final_text:\n",
    "                continue\n",
    "                \n",
    "            if len(final_text) >= 2:\n",
    "                final_text = selected_text.loc[selected_text['conf'].idxmax(),:].values.tolist()\n",
    "            else:\n",
    "                final_text = final_text[0]\n",
    "            \n",
    "            max_conf = final_text[0]\n",
    "            \n",
    "            \n",
    "            max_text = str(final_text[1]).lower()\n",
    "            if re.search(r'[^\\w\\s]', max_text):\n",
    "                max_text = re.sub(r'[^\\w\\s]', '',max_text)\n",
    "                \n",
    "            if max_text == '':\n",
    "                continue\n",
    "            \n",
    "            sub_results.append((img_id+1, (start_x, start_y, end_x, end_y), max_conf, max_text))\n",
    "        \n",
    "        sub_results = sorted(sub_results, key=lambda x: x[1][1])\n",
    "        \n",
    "        #Re-run with less strict parameters if <3 words identified\n",
    "        if len(sub_results) > 3:\n",
    "            \n",
    "            results.append(sub_results)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            \n",
    "            sub_results_lax = []\n",
    "            for i in indices:\n",
    "                center = boxes[i[0]][0]\n",
    "                w, h = boxes[i[0]][1]\n",
    "                angle = boxes[i[0]][2]\n",
    "\n",
    "                #Center of bounding boxes    \n",
    "                center_x, center_y = center\n",
    "                center_x = int(center_x)\n",
    "                center_y = int(center_y)\n",
    "\n",
    "                if w < h:\n",
    "                    w, h = h, w\n",
    "                    angle += 90.0\n",
    "\n",
    "                rows, cols, _ = image.shape\n",
    "\n",
    "                #Rotate bounding boxes that have angled text\n",
    "                matrix  = cv.getRotationMatrix2D(center, angle, 1)\n",
    "                rotated = cv.warpAffine(image, matrix, (cols, rows))\n",
    "\n",
    "                #padding\n",
    "                dX = int(w * padding_lax)\n",
    "                dY = int(h * padding_lax)\n",
    "\n",
    "                #Crop the rotated bounding box\n",
    "                start_y = int((center_y - (h / 2)) - dY)\n",
    "                end_y   = int((start_y + h) + (2 * dY))\n",
    "                start_x = int((center_x - (w / 2)) - dX)\n",
    "                end_x   = int((start_x + w) + (2 * dX))\n",
    "                start_x = start_x if 0 <= start_x < cols else (0 if start_x < 0 else cols-1)\n",
    "                end_x   = end_x if 0 <= end_x < cols else (0 if end_x < 0 else cols-1)\n",
    "                start_y = start_y if 0 <= start_y < rows else (0 if start_y < 0 else rows-1)\n",
    "                end_y   = end_y if 0 <= end_y < rows else (0 if end_y < 0 else rows-1)\n",
    "                crop    = rotated[start_y:end_y, start_x:end_x]\n",
    "\n",
    "                #Rescale very small bounding boxes to 32 height\n",
    "                if h < 32:\n",
    "\n",
    "                    crop = cv.resize(crop, None, fx=32/h, fy=32/h, interpolation=cv.INTER_CUBIC)\n",
    "\n",
    "                else:\n",
    "                    crop\n",
    "\n",
    "                #Configuration setting to convert image to string\n",
    "                #Chosen english and spanish\n",
    "                configuration = ('-l eng+spa --oem 1 --psm 6')\n",
    "\n",
    "                #Recognize the text from the bounding box image \n",
    "                text = pytesseract.image_to_data(crop, config=configuration, output_type='data.frame')\n",
    "                selected_text = text.loc[(text['conf'] > confTesseract_lax), ['conf','text']]\n",
    "                final_text = selected_text.values.tolist()\n",
    "\n",
    "                if not final_text:\n",
    "                    continue\n",
    "\n",
    "                if len(final_text) >= 2:\n",
    "                    final_text = selected_text.loc[selected_text['conf'].idxmax(),:].values.tolist()\n",
    "                else:\n",
    "                    final_text = final_text[0]\n",
    "\n",
    "                max_conf = final_text[0]\n",
    "\n",
    "\n",
    "                max_text = str(final_text[1]).lower()\n",
    "                if re.search(r'[^\\w\\s]', max_text):\n",
    "                    max_text = re.sub(r'[^\\w\\s]', '',max_text)\n",
    "                \n",
    "                if max_text == '':\n",
    "                    continue\n",
    "                \n",
    "                sub_results_lax.append((img_id+1, (start_x, start_y, end_x, end_y), max_conf, max_text))\n",
    "                \n",
    "            sub_results_lax = sorted(sub_results_lax, key=lambda x: x[1][1])\n",
    "            results.append(sub_results_lax)\n",
    "    yield results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779eb151",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8489ef9b",
   "metadata": {},
   "source": [
    "The results of all 303 images are captured below. For Part 2, I have compiled them into 303 rows with all text captured recorded under the 'text' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8c233a01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_id</th>\n",
       "      <th>bbox coord</th>\n",
       "      <th>conf</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>(274, 166, 350, 191)</td>\n",
       "      <td>92.0</td>\n",
       "      <td>elegant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>(454, 166, 493, 188)</td>\n",
       "      <td>86.0</td>\n",
       "      <td>yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>(191, 181, 238, 208)</td>\n",
       "      <td>86.0</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>(411, 199, 457, 221)</td>\n",
       "      <td>95.0</td>\n",
       "      <td>very</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>(196, 206, 244, 232)</td>\n",
       "      <td>94.0</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>303</td>\n",
       "      <td>(207, 629, 305, 643)</td>\n",
       "      <td>85.0</td>\n",
       "      <td>producer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>303</td>\n",
       "      <td>(301, 635, 389, 650)</td>\n",
       "      <td>89.0</td>\n",
       "      <td>fernando</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>303</td>\n",
       "      <td>(339, 653, 414, 668)</td>\n",
       "      <td>83.0</td>\n",
       "      <td>process</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>303</td>\n",
       "      <td>(411, 656, 474, 671)</td>\n",
       "      <td>96.0</td>\n",
       "      <td>washed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>303</td>\n",
       "      <td>(287, 771, 333, 786)</td>\n",
       "      <td>81.0</td>\n",
       "      <td>25090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4162 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    img_id            bbox coord  conf      text\n",
       "0        1  (274, 166, 350, 191)  92.0   elegant\n",
       "1        1  (454, 166, 493, 188)  86.0       yet\n",
       "2        1  (191, 181, 238, 208)  86.0       med\n",
       "3        1  (411, 199, 457, 221)  95.0      very\n",
       "4        1  (196, 206, 244, 232)  94.0       med\n",
       "..     ...                   ...   ...       ...\n",
       "8      303  (207, 629, 305, 643)  85.0  producer\n",
       "9      303  (301, 635, 389, 650)  89.0  fernando\n",
       "10     303  (339, 653, 414, 668)  83.0   process\n",
       "11     303  (411, 656, 474, 671)  96.0    washed\n",
       "12     303  (287, 771, 333, 786)  81.0     25090\n",
       "\n",
       "[4162 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run generator\n",
    "results = list(gen_recognition())\n",
    "\n",
    "#Update results into dataframe\n",
    "image_data = [x for x in results[0]]\n",
    "df_results = []\n",
    "for data in image_data:\n",
    "    data_results = pd.DataFrame(data, columns=['img_id','bbox coord', 'conf', 'text'])\n",
    "    df_results.append(data_results)\n",
    "\n",
    "\n",
    "#Summary of results    \n",
    "summary = pd.concat(df_results)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0250e1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace any blanks with nan and drop the row.\n",
    "\n",
    "summary['text'].replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2a5211ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.dropna(subset=['text'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e918d09",
   "metadata": {},
   "source": [
    "## Consolidate results and export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3bfa5f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_consolidated = summary.groupby('img_id')['text'].apply(lambda x: \"%s\" % ', '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "865e8ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_consolidated = pd.DataFrame(summary_consolidated, columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "924bc60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>elegant, yet, med, very, med, body, clean, bri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>wo, ardi, ethiopia, anic, orga, balance, indig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>kenya, karumandi, aa, 9090200, asted, roas, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>bona, ethiopia, honeysucki, earl, no, e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>drina, coffee, ia, 12010, whole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>299</td>\n",
       "      <td>mm, ethiopi, naturat, grams, 70, 283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>300</td>\n",
       "      <td>coffee, world, old, natural, rica, costa, don,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>301</td>\n",
       "      <td>method, natural, processing, mixed, 2000, laos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>302</td>\n",
       "      <td>parchmena, amayar, riack, black, harvest, 2020...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>303</td>\n",
       "      <td>e, fernando, truiillo, colombia, vanilla, tard...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     img_id                                               text\n",
       "0         1  elegant, yet, med, very, med, body, clean, bri...\n",
       "1         2  wo, ardi, ethiopia, anic, orga, balance, indig...\n",
       "2         3  kenya, karumandi, aa, 9090200, asted, roas, in...\n",
       "3         4            bona, ethiopia, honeysucki, earl, no, e\n",
       "4         5                    drina, coffee, ia, 12010, whole\n",
       "..      ...                                                ...\n",
       "298     299               mm, ethiopi, naturat, grams, 70, 283\n",
       "299     300  coffee, world, old, natural, rica, costa, don,...\n",
       "300     301  method, natural, processing, mixed, 2000, laos...\n",
       "301     302  parchmena, amayar, riack, black, harvest, 2020...\n",
       "302     303  e, fernando, truiillo, colombia, vanilla, tard...\n",
       "\n",
       "[303 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_consolidated.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4e853a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_consolidated.to_csv('consolidated_all_images_70pct_0311.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c8e94a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "consolidated = pd.read_csv('consolidated_all_images_70pct_0311.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604c8658",
   "metadata": {},
   "source": [
    "## Basic EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee3d01f",
   "metadata": {},
   "source": [
    "Not surprising, words like 'coffee', 'process', 'roasters' appear most frequently. 'Useful' words such as 'Ethiopia', 'natural', 'chocolate' are also captured quite a few times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fb2fefb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_id</th>\n",
       "      <th>bbox coord</th>\n",
       "      <th>conf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coffee</th>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>process</th>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roasters</th>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>washed</th>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ethiopia</th>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roasted</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>natural</th>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>notes</th>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>net</th>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chocolate</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>red</th>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whole</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roast</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>origin</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>honey</th>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filter</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variety</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>varietal</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>colombia</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>single</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>producer</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tasting</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>light</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caturra</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cherry</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dark</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bean</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           img_id  bbox coord  conf\n",
       "text                               \n",
       "coffee        127         127   127\n",
       "process        58          58    58\n",
       "roasters       55          55    55\n",
       "washed         53          53    53\n",
       "ethiopia       40          40    40\n",
       "roasted        39          39    39\n",
       "the            35          35    35\n",
       "natural        34          34    34\n",
       "and            32          32    32\n",
       "notes          31          31    31\n",
       "net            30          30    30\n",
       "chocolate      29          29    29\n",
       "red            28          28    28\n",
       "whole          27          27    27\n",
       "roast          26          26    26\n",
       "a              26          26    26\n",
       "la             23          23    23\n",
       "origin         23          23    23\n",
       "honey          22          22    22\n",
       "filter         21          21    21\n",
       "variety        20          20    20\n",
       "varietal       19          19    19\n",
       "colombia       18          18    18\n",
       "single         18          18    18\n",
       "producer       17          17    17\n",
       "this           16          16    16\n",
       "tasting        16          16    16\n",
       "y              16          16    16\n",
       "date           16          16    16\n",
       "light          15          15    15\n",
       "caturra        15          15    15\n",
       "cherry         15          15    15\n",
       "dark           15          15    15\n",
       "e              14          14    14\n",
       "bean           14          14    14"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.groupby('text').count().sort_values(by='conf',ascending=False).head(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74530e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ded92a5c",
   "metadata": {},
   "source": [
    "# Update in Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5c02c89d",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# #Display the image with bounding box and recognized text\n",
    "# orig_image = image.copy()\n",
    "\n",
    "# words = []\n",
    "# #Display text\n",
    "# for ((start_x, start_y, end_x, end_y), text) in results:\n",
    "      \n",
    "#     for each_word in text:\n",
    "#         if re.search(r'[:.,|]', str(each_word[1])):\n",
    "#             words.append(re.sub(r'[:.,|]','', str(each_word[1])))|\n",
    "#         else:\n",
    "#             words.append(each_word[1])\n",
    "\n",
    "#     cv.putText(orig_image, str(text), (start_x - 20, start_y - 10),\n",
    "#         cv.FONT_HERSHEY_SIMPLEX, 0.4,(0, 0, 255), 1)\n",
    "\n",
    "# #Display bounding boxes\n",
    "# for i in indices:\n",
    "#     # get 4 corners of the rotated rect\n",
    "#     vertices = cv.boxPoints(boxes[i[0]])\n",
    "#     # scale the bounding box coordinates based on the respective ratios\n",
    "#     for j in range(4):\n",
    "#         vertices[j][0] #*= rW\n",
    "#         vertices[j][1] #*= rH\n",
    "#     for j in range(4):\n",
    "#         p1 = (int(vertices[j][0]), int(vertices[j][1]))\n",
    "#         p2 = (int(vertices[(j + 1) % 4][0]), int(vertices[(j + 1) % 4][1]))\n",
    "#         cv.line(orig_image, p1, p2, (0, 255, 0), 1);\n",
    "\n",
    "    \n",
    "# print(words)\n",
    "# plt.figure(figsize = (10,10))\n",
    "# plt.imshow(orig_image)\n",
    "# plt.title('Output')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6c6c81",
   "metadata": {},
   "source": [
    "# TBC Merge Bounding Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "182a4f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_box = [bbox[0] for bbox in results]\n",
    "# text = [bbox[1] for bbox in results]\n",
    "\n",
    "# dist_limit = 10\n",
    "\n",
    "# #Copy of the text and object arrays\n",
    "# text_copied = copy.deepcopy(text)\n",
    "# text_box_copied = copy.deepcopy(text_box)\n",
    "\n",
    "# def merge_boxes(box1, box2):\n",
    "#     return [min(box1[0], box2[0]), \n",
    "#          min(box1[1], box2[1]), \n",
    "#          max(box1[2], box2[2]),\n",
    "#          max(box1[3], box2[3])]\n",
    "\n",
    "\n",
    "# def calc_sim(box1, box2):\n",
    "#     box1_xmin, box1_ymin, box1_xmax, box1_ymax  = box1\n",
    "#     box2_xmin, box2_ymin, box2_xmax, box2_ymax = box2\n",
    "\n",
    "#     x_dist = min(abs(box1_xmin-box2_xmin), abs(box1_xmin-box2_xmax), abs(box1_xmax-box2_xmin), abs(box1_xmax-box2_xmax))\n",
    "#     y_dist = min(abs(box1_ymin-box2_ymin), abs(box1_ymin-box2_ymax), abs(box1_ymax-box2_ymin), abs(box1_ymax-box2_ymax))\n",
    "\n",
    "#     dist = x_dist + y_dist\n",
    "#     return dist\n",
    "\n",
    "# #Function to merge text \n",
    "# def merge_algo(text, text_box):\n",
    "#     for i, (text_1, text_box_1) in enumerate(zip(text, text_box)):\n",
    "#         for j, (text_2, text_box_2) in enumerate(zip(text, text_box)):\n",
    "#             if j <= i:\n",
    "#                 continue\n",
    "#             # Create a new box if a distances is less than disctance limit defined \n",
    "#             if calc_sim(text_box_1, text_box_2) < dist_limit:\n",
    "#             # Create a new box  \n",
    "#                 new_box = merge_boxes(text_box_1, text_box_2)            \n",
    "#              # Create a new text string \n",
    "#                 new_text = text_1 + ' ' + text_2\n",
    "\n",
    "#                 text[i] = new_text\n",
    "#                 #delete previous text \n",
    "#                 del text[j]\n",
    "#                 text_box[i] = new_box\n",
    "#                 #delete previous text boxes\n",
    "#                 del text_box[j]\n",
    "#                 #return a new boxes and new text string that are close\n",
    "#                 return True, text, text_box\n",
    "\n",
    "#     return False, text, text_box\n",
    "\n",
    "# need_to_merge = True\n",
    "\n",
    "# #Merge full text \n",
    "# while need_to_merge:\n",
    "#     need_to_merge, text_copied, text_box_copied = merge_algo(text_copied, text_box_copied)\n",
    "\n",
    "# results1 = list(zip(text_box_copied, text_copied))\n",
    "# results1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8554387b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Display the image with bounding box and recognized text\n",
    "# orig_image = image.copy()\n",
    "\n",
    "# words = []\n",
    "# #Display text\n",
    "# for ((start_x, start_y, end_x, end_y), text) in results1:\n",
    "    \n",
    "#     #Remove words that Tesseract read from two lines due to lack of spacing\n",
    "#     if re.search(r'\\n\\w', text):\n",
    "#         pass\n",
    "    \n",
    "#     #Split words that have punctuation\n",
    "#     elif re.search(r'[:.,]', text):\n",
    "#         text_split = re.split(r'[:.,]', text)\n",
    "#         for split_word in text_split:\n",
    "#             words.append(re.sub(r'[\\n-\\x0c]','',split_word).strip(string.punctuation))\n",
    "#     else:\n",
    "#         words.append(re.sub('[\\n-\\x0c]','',text))\n",
    "\n",
    "#     text = \"\".join([x if ord(x) < 128 else \"\" for x in text]).strip()\n",
    "#     cv.putText(orig_image, text, (start_x - 20, start_y - 10),\n",
    "#         cv.FONT_HERSHEY_SIMPLEX, 0.4,(0, 0, 255), 1)\n",
    "\n",
    "# #Display bounding boxes\n",
    "# for i in indices:\n",
    "#     # get 4 corners of the rotated rect\n",
    "#     vertices = cv.boxPoints(boxes[i[0]])\n",
    "#     # scale the bounding box coordinates based on the respective ratios\n",
    "#     for j in range(4):\n",
    "#         vertices[j][0] #*= rW\n",
    "#         vertices[j][1] #*= rH\n",
    "#     for j in range(4):\n",
    "#         p1 = (int(vertices[j][0]), int(vertices[j][1]))\n",
    "#         p2 = (int(vertices[(j + 1) % 4][0]), int(vertices[(j + 1) % 4][1]))\n",
    "#         cv.line(orig_image, p1, p2, (0, 255, 0), 1);\n",
    "\n",
    "    \n",
    "# print(words)\n",
    "# plt.figure(figsize = (10,10))\n",
    "# plt.imshow(orig_image)\n",
    "# plt.title('Output')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
