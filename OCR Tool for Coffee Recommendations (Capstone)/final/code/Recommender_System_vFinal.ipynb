{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad5b9717",
   "metadata": {},
   "source": [
    "**Part 2**: Recommender System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4627aa",
   "metadata": {},
   "source": [
    "# Import Libraries / Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "598d6778",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminpoh/opt/anaconda3/envs/tensordsi24/lib/python3.7/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os, re\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense, Dropout, concatenate, multiply, Input, Reshape, dot, BatchNormalization, Activation\n",
    "from tensorflow.keras.optimizers import Adam#, SGD, RMSprop, Adadelta, Adamax, Adagrad\n",
    "from tensorflow.keras.losses import mean_squared_error as mse\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "\n",
    "import torch\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "\n",
    "import visualkeras\n",
    "\n",
    "pd.options.display.max_colwidth = 200\n",
    "\n",
    "def set_seed(seed_value=42):\n",
    "    '''Set seed for reproducibility'''\n",
    "    \n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "900d77ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sweetmarias = pd.read_csv('../data/cleaned_sweetmarias.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d933180",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sweetmarias.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bfadbb",
   "metadata": {},
   "source": [
    "# Brief Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7d763c",
   "metadata": {},
   "source": [
    "For Part 2, the aim is to leverage the text data from the OCR tool to generate recommendations of related coffees to buy from Sweet Marias. For example, if the OCR tool generates these words `['plum, berry, caturra, washed']`, we should ideally get recommendations on 5 coffees with very similar descriptions from Sweet Marias. The motivation for creating this OCR tool is to identify potential application in a real world setting. Recommending coffees to buy is just an avenue to commercialise this concept, and there are several possible areas to explore in the future (e.g. user reviews, social network).\n",
    "\n",
    "There are a few different NLP/deep-learning methods that I will try out in this section. These are a **baseline TF-IDF model**, a **feed-forward neural network auto-encoder**, a **Word2Vec model** and a **BERT transformer**.\n",
    "\n",
    "This will be a content-based recommender system and recommendations are ranked based on the cosine distance of the word vectors generated from the 'query' (OCR text) and each coffee description from Sweet Marias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3899a0",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a39bfb2",
   "metadata": {},
   "source": [
    "The dataset is pulled from Sweet Marias' website with the web-scraping notebook. It consists of 341 different coffee data scraped from SweetMarias in the 1st week of November 2021. The scraped data includes information such as country, region/farm, description of tasting notes, processing method and bean variety. For this project, I have chosen to combine *description*, *processing method* and *variety* as the 'document' for each coffee. Collectively, these 341 documents make up the corpus for this project. \n",
    "\n",
    "I have decided to exclude country and region/farm in the document because one of the intentions of the recommender system is to propose coffees based on the taste profile of the bean. For example, if the country 'Colombia' is part of the query sentence, having country names in each document will likely result in mostly Colombian coffees being the top 5 recommendations - while this might be perfect for someone looking for Colombian coffees, the intention of this recommender system is to prioritise tasting notes instead of country similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a412ba7",
   "metadata": {},
   "source": [
    "# Pre-processing & EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7172a9e6",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca42901f",
   "metadata": {},
   "source": [
    "In terms of pre-processing, there are a few basic text cleaning steps (lowercase text, removing \\n etc.) followed by simple tokenization (with the option of lemmatization). Tokenization will not apply to the BERT model as it has its own in-built tokenization process in the architecture offered by SentenceTransformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11241298",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stopwords to exclude\n",
    "\n",
    "new_stop_words = ['coffee','bean','beans','roaster','roasters','process','variety']\n",
    "total_stop_words = text.ENGLISH_STOP_WORDS.union(new_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa75d9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''Function to apply basic cleaning'''\n",
    "    \n",
    "    text = text.lower() #lowercase all text\n",
    "    text = re.sub(r'(\\r\\n|\\r|\\n)',' ',text) #remove \\r and \\n\n",
    "    text = re.sub(r'[^\\w\\s]',' ',text) #remove all non-alphanumeric characters\n",
    "    \n",
    "    #Apply stopwords\n",
    "    stopwords=total_stop_words\n",
    "    text = [i for i in text.split() if i not in stopwords]\n",
    "    text = ', '.join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "266ba6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(document, stopwords=total_stop_words, lemmatize=True):\n",
    "    '''Function to tokenize words with option to apply lemmatization'''\n",
    "    \n",
    "    doc = document.split(', ')\n",
    "    doc = ' '.join(doc)\n",
    "    \n",
    "    if lemmatize:\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        \n",
    "        tokens = [lemmatizer.lemmatize(i) for i in word_tokenize(doc)]\n",
    "    else:\n",
    "        tokens = [i for i in word_tokenize(doc)]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fcb0a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sweetmarias['cleaned_combined'] = df_sweetmarias['exlc_name_combined'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b04b9080",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sweetmarias['tok_lem_combined'] = df_sweetmarias['cleaned_combined'].apply(lambda x: tokenizer(x, stopwords=total_stop_words, lemmatize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e210c082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>URL</th>\n",
       "      <th>Description</th>\n",
       "      <th>Process</th>\n",
       "      <th>Variety</th>\n",
       "      <th>all_combined</th>\n",
       "      <th>exlc_name_combined</th>\n",
       "      <th>cleaned_combined</th>\n",
       "      <th>tok_lem_combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Burundi Commune Mutambu</td>\n",
       "      <td>https://www.sweetmarias.com/burundi-commune-mutambu-6644.html</td>\n",
       "      <td>Such a versatile Burundi, a neutral sweetness is accented by complex baking spices, creamed honey, loose leaf black tea and bittering cocoa when roasted dark. City to Full City+. Good for espresso.</td>\n",
       "      <td>Wet Washed</td>\n",
       "      <td>Bourbon</td>\n",
       "      <td>Burundi Commune Mutambu, Such a versatile Burundi, a neutral sweetness is accented by complex baking spices, creamed honey, loose leaf black tea and bittering cocoa when roasted dark. City to Full...</td>\n",
       "      <td>Such a versatile Burundi, a neutral sweetness is accented by complex baking spices, creamed honey, loose leaf black tea and bittering cocoa when roasted dark. City to Full City+. Good for espresso...</td>\n",
       "      <td>versatile, burundi, neutral, sweetness, accented, complex, baking, spices, creamed, honey, loose, leaf, black, tea, bittering, cocoa, roasted, dark, city, city, good, espresso, wet, washed, bourbon</td>\n",
       "      <td>[versatile, burundi, neutral, sweetness, accented, complex, baking, spice, creamed, honey, loose, leaf, black, tea, bittering, cocoa, roasted, dark, city, city, good, espresso, wet, washed, bourbon]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Burundi Dry Process Gaterama Agahore</td>\n",
       "      <td>https://www.sweetmarias.com/burundi-dry-process-gaterama-agahore-6751.html</td>\n",
       "      <td>Unapologetic \"dry process\" flavor that should satisfy those longing for berry-toned naturals ala \"Harrar\". Blackberry reduction, maple syrup, rustic dried fruit and earthy accents. City+ to Full C...</td>\n",
       "      <td>Dry Natural</td>\n",
       "      <td>Bourbon</td>\n",
       "      <td>Burundi Dry Process Gaterama Agahore, Unapologetic \"dry process\" flavor that should satisfy those longing for berry-toned naturals ala \"Harrar\". Blackberry reduction, maple syrup, rustic dried fru...</td>\n",
       "      <td>Unapologetic \"dry process\" flavor that should satisfy those longing for berry-toned naturals ala \"Harrar\". Blackberry reduction, maple syrup, rustic dried fruit and earthy accents. City+ to Full C...</td>\n",
       "      <td>unapologetic, dry, flavor, satisfy, longing, berry, toned, naturals, ala, harrar, blackberry, reduction, maple, syrup, rustic, dried, fruit, earthy, accents, city, city, dry, natural, bourbon</td>\n",
       "      <td>[unapologetic, dry, flavor, satisfy, longing, berry, toned, natural, ala, harrar, blackberry, reduction, maple, syrup, rustic, dried, fruit, earthy, accent, city, city, dry, natural, bourbon]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Burundi Dry Process Kibingo</td>\n",
       "      <td>https://www.sweetmarias.com/burundi-dry-process-kibingo-6749.html</td>\n",
       "      <td>Cooked fruit and wheat flavors that bring to mind raspberry pie, hints of barley malt syrup and dried prune. Soft acidity and bittersweet at Full City, a note of dark cacao bar with crisped rice. ...</td>\n",
       "      <td>Dry Natural</td>\n",
       "      <td>Bourbon</td>\n",
       "      <td>Burundi Dry Process Kibingo, Cooked fruit and wheat flavors that bring to mind raspberry pie, hints of barley malt syrup and dried prune. Soft acidity and bittersweet at Full City, a note of dark ...</td>\n",
       "      <td>Cooked fruit and wheat flavors that bring to mind raspberry pie, hints of barley malt syrup and dried prune. Soft acidity and bittersweet at Full City, a note of dark cacao bar with crisped rice. ...</td>\n",
       "      <td>cooked, fruit, wheat, flavors, bring, mind, raspberry, pie, hints, barley, malt, syrup, dried, prune, soft, acidity, bittersweet, city, note, dark, cacao, bar, crisped, rice, city, city, dry, natu...</td>\n",
       "      <td>[cooked, fruit, wheat, flavor, bring, mind, raspberry, pie, hint, barley, malt, syrup, dried, prune, soft, acidity, bittersweet, city, note, dark, cacao, bar, crisped, rice, city, city, dry, natur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Burundi Honey Process Gahahe</td>\n",
       "      <td>https://www.sweetmarias.com/burundi-honey-process-gahahe-6747.html</td>\n",
       "      <td>Sweet, clean cup character like wet process Burundi, burned sugar sweetness, bergamot orange aroma, old fashioned spice cookies, and an acidic impression like strong black tea. City to Full City. ...</td>\n",
       "      <td>Honey</td>\n",
       "      <td>Bourbon</td>\n",
       "      <td>Burundi Honey Process Gahahe, Sweet, clean cup character like wet process Burundi, burned sugar sweetness, bergamot orange aroma, old fashioned spice cookies, and an acidic impression like strong ...</td>\n",
       "      <td>Sweet, clean cup character like wet process Burundi, burned sugar sweetness, bergamot orange aroma, old fashioned spice cookies, and an acidic impression like strong black tea. City to Full City. ...</td>\n",
       "      <td>sweet, clean, cup, character, like, wet, burundi, burned, sugar, sweetness, bergamot, orange, aroma, old, fashioned, spice, cookies, acidic, impression, like, strong, black, tea, city, city, good,...</td>\n",
       "      <td>[sweet, clean, cup, character, like, wet, burundi, burned, sugar, sweetness, bergamot, orange, aroma, old, fashioned, spice, cooky, acidic, impression, like, strong, black, tea, city, city, good, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Burundi Kabarore Commune Yandaro</td>\n",
       "      <td>https://www.sweetmarias.com/burundi-kabarore-commune-yandaro-6746.html</td>\n",
       "      <td>Lighter roasts draw out potent aromatic, like whole clove and all spice, unrefined molasses sweetness, cola, and a brisk flavor of black tea with lemon. City to Full City+. Good for espresso.</td>\n",
       "      <td>Wet Washed</td>\n",
       "      <td>Bourbon</td>\n",
       "      <td>Burundi Kabarore Commune Yandaro, Lighter roasts draw out potent aromatic, like whole clove and all spice, unrefined molasses sweetness, cola, and a brisk flavor of black tea with lemon. City to F...</td>\n",
       "      <td>Lighter roasts draw out potent aromatic, like whole clove and all spice, unrefined molasses sweetness, cola, and a brisk flavor of black tea with lemon. City to Full City+. Good for espresso., Wet...</td>\n",
       "      <td>lighter, roasts, draw, potent, aromatic, like, clove, spice, unrefined, molasses, sweetness, cola, brisk, flavor, black, tea, lemon, city, city, good, espresso, wet, washed, bourbon</td>\n",
       "      <td>[lighter, roast, draw, potent, aromatic, like, clove, spice, unrefined, molasses, sweetness, cola, brisk, flavor, black, tea, lemon, city, city, good, espresso, wet, washed, bourbon]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Name  \\\n",
       "0               Burundi Commune Mutambu   \n",
       "1  Burundi Dry Process Gaterama Agahore   \n",
       "2           Burundi Dry Process Kibingo   \n",
       "3          Burundi Honey Process Gahahe   \n",
       "4      Burundi Kabarore Commune Yandaro   \n",
       "\n",
       "                                                                          URL  \\\n",
       "0               https://www.sweetmarias.com/burundi-commune-mutambu-6644.html   \n",
       "1  https://www.sweetmarias.com/burundi-dry-process-gaterama-agahore-6751.html   \n",
       "2           https://www.sweetmarias.com/burundi-dry-process-kibingo-6749.html   \n",
       "3          https://www.sweetmarias.com/burundi-honey-process-gahahe-6747.html   \n",
       "4      https://www.sweetmarias.com/burundi-kabarore-commune-yandaro-6746.html   \n",
       "\n",
       "                                                                                                                                                                                               Description  \\\n",
       "0    Such a versatile Burundi, a neutral sweetness is accented by complex baking spices, creamed honey, loose leaf black tea and bittering cocoa when roasted dark. City to Full City+. Good for espresso.   \n",
       "1  Unapologetic \"dry process\" flavor that should satisfy those longing for berry-toned naturals ala \"Harrar\". Blackberry reduction, maple syrup, rustic dried fruit and earthy accents. City+ to Full C...   \n",
       "2  Cooked fruit and wheat flavors that bring to mind raspberry pie, hints of barley malt syrup and dried prune. Soft acidity and bittersweet at Full City, a note of dark cacao bar with crisped rice. ...   \n",
       "3  Sweet, clean cup character like wet process Burundi, burned sugar sweetness, bergamot orange aroma, old fashioned spice cookies, and an acidic impression like strong black tea. City to Full City. ...   \n",
       "4          Lighter roasts draw out potent aromatic, like whole clove and all spice, unrefined molasses sweetness, cola, and a brisk flavor of black tea with lemon. City to Full City+. Good for espresso.   \n",
       "\n",
       "       Process  Variety  \\\n",
       "0   Wet Washed  Bourbon   \n",
       "1  Dry Natural  Bourbon   \n",
       "2  Dry Natural  Bourbon   \n",
       "3        Honey  Bourbon   \n",
       "4   Wet Washed  Bourbon   \n",
       "\n",
       "                                                                                                                                                                                              all_combined  \\\n",
       "0  Burundi Commune Mutambu, Such a versatile Burundi, a neutral sweetness is accented by complex baking spices, creamed honey, loose leaf black tea and bittering cocoa when roasted dark. City to Full...   \n",
       "1  Burundi Dry Process Gaterama Agahore, Unapologetic \"dry process\" flavor that should satisfy those longing for berry-toned naturals ala \"Harrar\". Blackberry reduction, maple syrup, rustic dried fru...   \n",
       "2  Burundi Dry Process Kibingo, Cooked fruit and wheat flavors that bring to mind raspberry pie, hints of barley malt syrup and dried prune. Soft acidity and bittersweet at Full City, a note of dark ...   \n",
       "3  Burundi Honey Process Gahahe, Sweet, clean cup character like wet process Burundi, burned sugar sweetness, bergamot orange aroma, old fashioned spice cookies, and an acidic impression like strong ...   \n",
       "4  Burundi Kabarore Commune Yandaro, Lighter roasts draw out potent aromatic, like whole clove and all spice, unrefined molasses sweetness, cola, and a brisk flavor of black tea with lemon. City to F...   \n",
       "\n",
       "                                                                                                                                                                                        exlc_name_combined  \\\n",
       "0  Such a versatile Burundi, a neutral sweetness is accented by complex baking spices, creamed honey, loose leaf black tea and bittering cocoa when roasted dark. City to Full City+. Good for espresso...   \n",
       "1  Unapologetic \"dry process\" flavor that should satisfy those longing for berry-toned naturals ala \"Harrar\". Blackberry reduction, maple syrup, rustic dried fruit and earthy accents. City+ to Full C...   \n",
       "2  Cooked fruit and wheat flavors that bring to mind raspberry pie, hints of barley malt syrup and dried prune. Soft acidity and bittersweet at Full City, a note of dark cacao bar with crisped rice. ...   \n",
       "3  Sweet, clean cup character like wet process Burundi, burned sugar sweetness, bergamot orange aroma, old fashioned spice cookies, and an acidic impression like strong black tea. City to Full City. ...   \n",
       "4  Lighter roasts draw out potent aromatic, like whole clove and all spice, unrefined molasses sweetness, cola, and a brisk flavor of black tea with lemon. City to Full City+. Good for espresso., Wet...   \n",
       "\n",
       "                                                                                                                                                                                          cleaned_combined  \\\n",
       "0    versatile, burundi, neutral, sweetness, accented, complex, baking, spices, creamed, honey, loose, leaf, black, tea, bittering, cocoa, roasted, dark, city, city, good, espresso, wet, washed, bourbon   \n",
       "1          unapologetic, dry, flavor, satisfy, longing, berry, toned, naturals, ala, harrar, blackberry, reduction, maple, syrup, rustic, dried, fruit, earthy, accents, city, city, dry, natural, bourbon   \n",
       "2  cooked, fruit, wheat, flavors, bring, mind, raspberry, pie, hints, barley, malt, syrup, dried, prune, soft, acidity, bittersweet, city, note, dark, cacao, bar, crisped, rice, city, city, dry, natu...   \n",
       "3  sweet, clean, cup, character, like, wet, burundi, burned, sugar, sweetness, bergamot, orange, aroma, old, fashioned, spice, cookies, acidic, impression, like, strong, black, tea, city, city, good,...   \n",
       "4                    lighter, roasts, draw, potent, aromatic, like, clove, spice, unrefined, molasses, sweetness, cola, brisk, flavor, black, tea, lemon, city, city, good, espresso, wet, washed, bourbon   \n",
       "\n",
       "                                                                                                                                                                                          tok_lem_combined  \n",
       "0   [versatile, burundi, neutral, sweetness, accented, complex, baking, spice, creamed, honey, loose, leaf, black, tea, bittering, cocoa, roasted, dark, city, city, good, espresso, wet, washed, bourbon]  \n",
       "1          [unapologetic, dry, flavor, satisfy, longing, berry, toned, natural, ala, harrar, blackberry, reduction, maple, syrup, rustic, dried, fruit, earthy, accent, city, city, dry, natural, bourbon]  \n",
       "2  [cooked, fruit, wheat, flavor, bring, mind, raspberry, pie, hint, barley, malt, syrup, dried, prune, soft, acidity, bittersweet, city, note, dark, cacao, bar, crisped, rice, city, city, dry, natur...  \n",
       "3  [sweet, clean, cup, character, like, wet, burundi, burned, sugar, sweetness, bergamot, orange, aroma, old, fashioned, spice, cooky, acidic, impression, like, strong, black, tea, city, city, good, ...  \n",
       "4                   [lighter, roast, draw, potent, aromatic, like, clove, spice, unrefined, molasses, sweetness, cola, brisk, flavor, black, tea, lemon, city, city, good, espresso, wet, washed, bourbon]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sweetmarias.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d17897",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad6c4e9",
   "metadata": {},
   "source": [
    "**Average length of sentence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2d77c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 words\n"
     ]
    }
   ],
   "source": [
    "doc_length = []\n",
    "for document in range(len(df_sweetmarias['tok_lem_combined'])):\n",
    "    doc_length.append(len(df_sweetmarias['tok_lem_combined'][document]))\n",
    "\n",
    "avg_doc_length = sum(doc_length)/len(doc_length)\n",
    "print(f'{round(avg_doc_length)}' + ' words')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f66fb75",
   "metadata": {},
   "source": [
    "**Most Common Words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b67f2db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city         724\n",
       "wet          253\n",
       "washed       248\n",
       "note         230\n",
       "bourbon      175\n",
       "espresso     172\n",
       "flavor       169\n",
       "sweetness    167\n",
       "good         165\n",
       "sugar        162\n",
       "roast        149\n",
       "chocolate    136\n",
       "hybrid       130\n",
       "modern       128\n",
       "hint         119\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = []\n",
    "for document in range(len(df_sweetmarias['tok_lem_combined'])):\n",
    "    for word in df_sweetmarias['tok_lem_combined'][document]:\n",
    "        words.append(word)\n",
    "        \n",
    "words = pd.DataFrame(words)\n",
    "words.value_counts().head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1a601d",
   "metadata": {},
   "source": [
    "# Query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be837ee2",
   "metadata": {},
   "source": [
    "This is an example query that we will run through for the four models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d6e62cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'plum, berry, caturra, washed'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f12253d",
   "metadata": {},
   "source": [
    "# TF-IDF (Baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6d2774",
   "metadata": {},
   "source": [
    "Term Frequency Inverse Document Frequency (TF-IDF) is one of the easiest and fastest ways to analyse the relevance of a term (word) in a given document. It gives a numerical weightage of words (to reflect its importance in the document), and weighs down the frequently occurings words to identify the difference between one document and another. However, as a simple model, it does not understand semantics, synonyms or other nuances in language.\n",
    "\n",
    "We will be using the TF-IDF as a baseline model to compare against the other more complex models. As much as it is a corpus exploration method, TF-IDF is also used as a pre-processing step for other models. Therefore, we will also be using the TF-IDF matrix as a pre-processed input for the auto-encoder model that I've built in the later section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8706f7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_coffee_from_description_tfidf(query, model_embed):\n",
    "    '''Function to calculate cosine similarity and return top 5 recommendations'''\n",
    "    \n",
    "    #Embed query\n",
    "    clean_query = clean_text(query)\n",
    "    vectorize_query = tfidf.transform([clean_query]) #apply tfidf transform on query\n",
    "    \n",
    "    print(f'Query: {clean_query}')\n",
    "    \n",
    "    #Matrix of similarity between query and database\n",
    "    similarity_matrix = pd.DataFrame(cosine_similarity(vectorize_query, model_embed))\n",
    "    \n",
    "    #New column of 'similarity_score'\n",
    "    similar_items = pd.DataFrame(similarity_matrix.T)\n",
    "    similar_items.columns = [\"similarity_score\"]\n",
    "    similar_items = similar_items.sort_values('similarity_score', ascending=False)\n",
    "    similar_items.reset_index(inplace=True)\n",
    "    \n",
    "    #Use index as an 'item_id' \n",
    "    similar_items = similar_items.rename(index=str, columns={\"index\": \"item_id\"})\n",
    "    similar_coffees = pd.DataFrame(similar_items.to_dict())\n",
    "    similar_coffees.set_index('item_id', inplace=True)\n",
    "    \n",
    "    #List top recommendations \n",
    "    similar_df = pd.merge(df_sweetmarias, similar_coffees, left_index=True, right_index=True)\n",
    "    similar_df.sort_values('similarity_score', ascending=False, inplace=True)\n",
    "    return similar_df[['Name','Description','Process','Variety','similarity_score']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bbea7067",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the documents from the 'tok_lem_combined' column from the pre-processing step\n",
    "\n",
    "df_sweetmarias['tfidf_lem_combined'] = df_sweetmarias['tok_lem_combined'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3fa84206",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn's TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words=total_stop_words, binary=True)\n",
    "tfidf_matrix = tfidf.fit_transform(df_sweetmarias['tfidf_lem_combined'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4baa9ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix_array = tfidf_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe67c272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: plum, berry, caturra, washed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Process</th>\n",
       "      <th>Variety</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>Colombia Urrao Valle de Penderisco</td>\n",
       "      <td>Brown sugar and roast bittering low tones open up to accents of red berry, date syrup, plum, sweetened cocoa, and black tea-like acidity that's somewhere between mild and moderate. City to Full Ci...</td>\n",
       "      <td>Wet Washed</td>\n",
       "      <td>Caturra, Typica</td>\n",
       "      <td>0.329859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>Colombia Urrao Valle de Penderisco</td>\n",
       "      <td>Molasses, demurara sugar, moderate brightness, accents of berry and hibiscus flower tea. Dark roasts boast heavy-handed cocoa roast flavors and plum. City+ to Full City+. Good for espresso.</td>\n",
       "      <td>Wet Washed</td>\n",
       "      <td>Caturra, Bourbon, Heirloom</td>\n",
       "      <td>0.304093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>Colombia Caicedo Las Alegrias</td>\n",
       "      <td>A cup with intimations of dried fruit against a backdrop of rustic, unrefined sugar sweetness, hints of dried raisin and plum, tea-like tannic acidity. Chocolatey dark roast. City to Full City+.</td>\n",
       "      <td>Wet Washed</td>\n",
       "      <td>Caturra, Typica, Modern Hybrids</td>\n",
       "      <td>0.253538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Guatemala Proyecto Xinabajul Donaldo Villatoro</td>\n",
       "      <td>An aromatic Guatemalan coffee with brisk acidity, toasted sugar sweetness, and flavor notes of warming spices, Earl Grey tea, dried plum and milk chocolate. City to Full City.</td>\n",
       "      <td>Wet Washed</td>\n",
       "      <td>Caturra, Bourbon, Typica</td>\n",
       "      <td>0.252061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Rwanda Dry Process Nyakabingo</td>\n",
       "      <td>Middle roasts move beyond molasses sweetness, to fruit and spice flavors, notes of berry-infused dark chocolate, plum, overripe citrus, and a hint of heart of palm in the finish. City+ to Full City.</td>\n",
       "      <td>Dry Natural</td>\n",
       "      <td>Bourbon</td>\n",
       "      <td>0.251311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Name  \\\n",
       "329              Colombia Urrao Valle de Penderisco   \n",
       "328              Colombia Urrao Valle de Penderisco   \n",
       "305                   Colombia Caicedo Las Alegrias   \n",
       "186  Guatemala Proyecto Xinabajul Donaldo Villatoro   \n",
       "105                   Rwanda Dry Process Nyakabingo   \n",
       "\n",
       "                                                                                                                                                                                                 Description  \\\n",
       "329  Brown sugar and roast bittering low tones open up to accents of red berry, date syrup, plum, sweetened cocoa, and black tea-like acidity that's somewhere between mild and moderate. City to Full Ci...   \n",
       "328            Molasses, demurara sugar, moderate brightness, accents of berry and hibiscus flower tea. Dark roasts boast heavy-handed cocoa roast flavors and plum. City+ to Full City+. Good for espresso.   \n",
       "305       A cup with intimations of dried fruit against a backdrop of rustic, unrefined sugar sweetness, hints of dried raisin and plum, tea-like tannic acidity. Chocolatey dark roast. City to Full City+.   \n",
       "186                          An aromatic Guatemalan coffee with brisk acidity, toasted sugar sweetness, and flavor notes of warming spices, Earl Grey tea, dried plum and milk chocolate. City to Full City.   \n",
       "105   Middle roasts move beyond molasses sweetness, to fruit and spice flavors, notes of berry-infused dark chocolate, plum, overripe citrus, and a hint of heart of palm in the finish. City+ to Full City.   \n",
       "\n",
       "         Process                          Variety  similarity_score  \n",
       "329   Wet Washed                  Caturra, Typica          0.329859  \n",
       "328   Wet Washed       Caturra, Bourbon, Heirloom          0.304093  \n",
       "305   Wet Washed  Caturra, Typica, Modern Hybrids          0.253538  \n",
       "186   Wet Washed         Caturra, Bourbon, Typica          0.252061  \n",
       "105  Dry Natural                          Bourbon          0.251311  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Top 5 recommended coffees\n",
    "\n",
    "recommend_coffee_from_description_tfidf(query, tfidf_matrix_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78235ba5",
   "metadata": {},
   "source": [
    "# Auto-Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f661de",
   "metadata": {},
   "source": [
    "An auto-encoder is an unsupervised neural network that learns how to efficiently compress and encode data, and then learns how to reconstruct this data back from the its reduced encoded form to one that is as close to the original input as possible. The aim is to minimise the reconstruction error (the difference between original input and reconstruction) via back progation during the training process. By 'compressing' the input, we are forcing the model to learn useful information by filtering out noise from the data. The output for the model is at the 'compressed' layer called the bottleneck, and this is where we extract the information for predictions later on. Background details are from [here](https://towardsdatascience.com/auto-encoder-what-is-it-and-what-is-it-used-for-part-1-3e5c6f017726) and [here](https://machinelearningmastery.com/autoencoder-for-classification/).\n",
    "\n",
    "Auto-encoders can be deployed using different architectures - feed-forward network, LTSM, CNN etc. For this project, I have trained a simple feed-forward network of 6 layers as a comparison to see how effective it is versus other state of the art architectures. While auto-encoders are usually used for image classification problems, there are several research papers exploring its use in the semantic text similarity space (e.g. [Amiri et al., 2016](https://scholar.harvard.edu/files/hadi/files/amiri-acl-16.pdf) and [Mandic, 2018](https://helda.helsinki.fi/bitstream/handle/10138/273571/grappa_files_17_08_2018.pdf?sequence=2&isAllowed=y)). For semantic text similarity problems, the idea is that if a model is able to provide a good reconstruction of the input (in this case, the documents in the corpus), it should have retained the good information (what's different/similar) of the input, and therefore have become a context-sensitive representation of the data.\n",
    "\n",
    "In my model, I have added dropout layers to prevent overfitting since the dataset that I have used is relatively small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "634a675d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_coffee_from_description_ae(query, auto_encode_embedding):\n",
    "    \n",
    "    #Embed query\n",
    "    clean_query = clean_text(query)\n",
    "    vectorize_query = tfidf.transform([clean_query]) #apply tfidf transform on query\n",
    "    \n",
    "    print(f'Query: {clean_query}')\n",
    "    \n",
    "    #Predict\n",
    "    query_predict = embedding.predict(vectorize_query)\n",
    "    \n",
    "    #Matrix of similarity between query and database\n",
    "    similarity_matrix = pd.DataFrame(cosine_similarity(\n",
    "            query_predict,auto_encode_embedding))\n",
    "    \n",
    "    #New column of 'similarity_score'\n",
    "    similar_items = pd.DataFrame(similarity_matrix.T)\n",
    "    similar_items.columns = [\"similarity_score\"]\n",
    "    similar_items = similar_items.sort_values('similarity_score', ascending=False)\n",
    "    similar_items.reset_index(inplace=True)\n",
    "    \n",
    "    #Use index as an 'item_id' \n",
    "    similar_items = similar_items.rename(index=str, columns={\"index\": \"item_id\"})\n",
    "    similar_coffees = pd.DataFrame(similar_items.to_dict())\n",
    "    similar_coffees.set_index('item_id', inplace=True)\n",
    "    \n",
    "    #List top recommendations \n",
    "    similar_df = pd.merge(df_sweetmarias, similar_coffees, left_index=True, right_index=True)\n",
    "    similar_df.sort_values('similarity_score', ascending=False, inplace=True)\n",
    "    return similar_df[['Name','Description','Process','Variety','similarity_score']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f931803",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "input_size = tfidf_matrix_array.shape[1]\n",
    "intermediate_size = 512\n",
    "intermediate_2_size =256\n",
    "code_size = 48\n",
    "\n",
    "def auto_encoder():\n",
    "    \n",
    "    #Encode\n",
    "    model = Sequential()\n",
    "    model.add(Dense(intermediate_size,input_shape=(input_size,))) \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(BatchNormalization(axis=1, name='bn_encoder1'))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    \n",
    "    model.add(Dense(intermediate_2_size))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(BatchNormalization(axis=1, name='bn_encoder2'))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    #bottleneck\n",
    "    model.add(Dense(code_size))\n",
    "    model.add(Activation('relu', name='bottleneck'))\n",
    "    \n",
    "    #Decode\n",
    "    model.add(Dense(intermediate_2_size))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(BatchNormalization(axis=1, name='bn_decoder1'))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    \n",
    "    model.add(Dense(intermediate_size))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(BatchNormalization(axis=1, name='bn_decoder2'))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dense(input_size,))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7dc29ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-11 01:16:08.303325: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-11 01:16:08.303579: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 8. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "auto_encode = auto_encoder() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3089bf7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               561152    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "bn_encoder1 (BatchNormalizat (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "bn_encoder2 (BatchNormalizat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 48)                12336     \n",
      "_________________________________________________________________\n",
      "bottleneck (Activation)      (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               12544     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "bn_decoder1 (BatchNormalizat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "bn_decoder2 (BatchNormalizat (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1095)              561735    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1095)              0         \n",
      "=================================================================\n",
      "Total params: 1,416,823\n",
      "Trainable params: 1,413,751\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "auto_encode.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "36de466d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(tfidf_matrix_array, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba5654ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 258 samples, validate on 86 samples\n",
      "Epoch 1/70\n",
      "192/258 [=====================>........] - ETA: 1s - loss: 0.2201\n",
      "Epoch 00001: val_loss improved from inf to 0.24137, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 4s 14ms/sample - loss: 0.2003 - val_loss: 0.2414\n",
      "Epoch 2/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 0.0708\n",
      "Epoch 00002: val_loss improved from 0.24137 to 0.22459, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 0.0629 - val_loss: 0.2246\n",
      "Epoch 3/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 0.0192\n",
      "Epoch 00003: val_loss improved from 0.22459 to 0.19688, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 0.0172 - val_loss: 0.1969\n",
      "Epoch 4/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 0.0064\n",
      "Epoch 00004: val_loss improved from 0.19688 to 0.16303, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 0.0059 - val_loss: 0.1630\n",
      "Epoch 5/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 0.0032\n",
      "Epoch 00005: val_loss improved from 0.16303 to 0.12983, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 0.0030 - val_loss: 0.1298\n",
      "Epoch 6/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 0.0021\n",
      "Epoch 00006: val_loss improved from 0.12983 to 0.10072, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 0.0020 - val_loss: 0.1007\n",
      "Epoch 7/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 0.0017\n",
      "Epoch 00007: val_loss improved from 0.10072 to 0.07711, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 0.0017 - val_loss: 0.0771\n",
      "Epoch 8/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 0.0015\n",
      "Epoch 00008: val_loss improved from 0.07711 to 0.05867, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 0.0015 - val_loss: 0.0587\n",
      "Epoch 9/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 0.0013\n",
      "Epoch 00009: val_loss improved from 0.05867 to 0.04464, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 0.0013 - val_loss: 0.0446\n",
      "Epoch 10/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 0.0013\n",
      "Epoch 00010: val_loss improved from 0.04464 to 0.03427, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 0.0013 - val_loss: 0.0343\n",
      "Epoch 11/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 0.0012\n",
      "Epoch 00011: val_loss improved from 0.03427 to 0.02627, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 0.0012 - val_loss: 0.0263\n",
      "Epoch 12/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 0.0012\n",
      "Epoch 00012: val_loss improved from 0.02627 to 0.02035, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 0.0012 - val_loss: 0.0204\n",
      "Epoch 13/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 0.0012\n",
      "Epoch 00013: val_loss improved from 0.02035 to 0.01603, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 0.0012 - val_loss: 0.0160\n",
      "Epoch 14/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 0.0012\n",
      "Epoch 00014: val_loss improved from 0.01603 to 0.01254, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 0.0012 - val_loss: 0.0125\n",
      "Epoch 15/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 0.0011\n",
      "Epoch 00015: val_loss improved from 0.01254 to 0.01005, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 0.0011 - val_loss: 0.0101\n",
      "Epoch 16/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 0.0011\n",
      "Epoch 00016: val_loss improved from 0.01005 to 0.00815, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 0.0011 - val_loss: 0.0081\n",
      "Epoch 17/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 0.0011\n",
      "Epoch 00017: val_loss improved from 0.00815 to 0.00663, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 0.0011 - val_loss: 0.0066\n",
      "Epoch 18/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 0.0011\n",
      "Epoch 00018: val_loss improved from 0.00663 to 0.00554, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 0.0011 - val_loss: 0.0055\n",
      "Epoch 19/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 0.0011\n",
      "Epoch 00019: val_loss improved from 0.00554 to 0.00464, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 20/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 0.0011\n",
      "Epoch 00020: val_loss improved from 0.00464 to 0.00394, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 0.0011 - val_loss: 0.0039\n",
      "Epoch 21/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 0.0011\n",
      "Epoch 00021: val_loss improved from 0.00394 to 0.00343, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 0.0011 - val_loss: 0.0034\n",
      "Epoch 22/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 0.0011\n",
      "Epoch 00022: val_loss improved from 0.00343 to 0.00300, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 2ms/sample - loss: 0.0011 - val_loss: 0.0030\n",
      "Epoch 23/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 0.0011\n",
      "Epoch 00023: val_loss improved from 0.00300 to 0.00265, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 0.0011 - val_loss: 0.0026\n",
      "Epoch 24/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 0.0011\n",
      "Epoch 00024: val_loss improved from 0.00265 to 0.00237, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 0.0011 - val_loss: 0.0024\n",
      "Epoch 25/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 0.0011\n",
      "Epoch 00025: val_loss improved from 0.00237 to 0.00214, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 26/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 0.0010\n",
      "Epoch 00026: val_loss improved from 0.00214 to 0.00196, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 0.0010 - val_loss: 0.0020\n",
      "Epoch 27/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 0.0010\n",
      "Epoch 00027: val_loss improved from 0.00196 to 0.00183, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 28/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 0.0010\n",
      "Epoch 00028: val_loss improved from 0.00183 to 0.00172, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 29/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 0.0010\n",
      "Epoch 00029: val_loss improved from 0.00172 to 0.00162, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 30/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 0.0010\n",
      "Epoch 00030: val_loss improved from 0.00162 to 0.00154, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 0.0010 - val_loss: 0.0015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 0.0010\n",
      "Epoch 00031: val_loss improved from 0.00154 to 0.00146, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 32/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 0.0010\n",
      "Epoch 00032: val_loss improved from 0.00146 to 0.00141, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 33/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 0.0010\n",
      "Epoch 00033: val_loss improved from 0.00141 to 0.00135, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 34/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 0.0010\n",
      "Epoch 00034: val_loss improved from 0.00135 to 0.00129, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 35/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 9.9657e-04\n",
      "Epoch 00035: val_loss improved from 0.00129 to 0.00126, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 9.9803e-04 - val_loss: 0.0013\n",
      "Epoch 36/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 9.9486e-04\n",
      "Epoch 00036: val_loss improved from 0.00126 to 0.00122, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 9.9144e-04 - val_loss: 0.0012\n",
      "Epoch 37/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 9.7958e-04\n",
      "Epoch 00037: val_loss improved from 0.00122 to 0.00119, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 9.7898e-04 - val_loss: 0.0012\n",
      "Epoch 38/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 9.8540e-04\n",
      "Epoch 00038: val_loss improved from 0.00119 to 0.00116, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 9.8307e-04 - val_loss: 0.0012\n",
      "Epoch 39/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 9.7859e-04\n",
      "Epoch 00039: val_loss improved from 0.00116 to 0.00114, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 9.7463e-04 - val_loss: 0.0011\n",
      "Epoch 40/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 9.7647e-04\n",
      "Epoch 00040: val_loss improved from 0.00114 to 0.00113, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 9.7242e-04 - val_loss: 0.0011\n",
      "Epoch 41/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 9.7064e-04\n",
      "Epoch 00041: val_loss improved from 0.00113 to 0.00112, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 9.6977e-04 - val_loss: 0.0011\n",
      "Epoch 42/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 9.6004e-04\n",
      "Epoch 00042: val_loss improved from 0.00112 to 0.00111, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 9.6331e-04 - val_loss: 0.0011\n",
      "Epoch 43/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 9.6420e-04\n",
      "Epoch 00043: val_loss improved from 0.00111 to 0.00109, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 9.6412e-04 - val_loss: 0.0011\n",
      "Epoch 44/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 9.5412e-04\n",
      "Epoch 00044: val_loss improved from 0.00109 to 0.00108, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 9.5320e-04 - val_loss: 0.0011\n",
      "Epoch 45/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 9.6203e-04\n",
      "Epoch 00045: val_loss improved from 0.00108 to 0.00107, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 9.6045e-04 - val_loss: 0.0011\n",
      "Epoch 46/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 9.5191e-04\n",
      "Epoch 00046: val_loss improved from 0.00107 to 0.00106, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 9.4991e-04 - val_loss: 0.0011\n",
      "Epoch 47/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 9.5476e-04\n",
      "Epoch 00047: val_loss improved from 0.00106 to 0.00105, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 9.5270e-04 - val_loss: 0.0011\n",
      "Epoch 48/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 9.5423e-04\n",
      "Epoch 00048: val_loss improved from 0.00105 to 0.00104, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 9.5536e-04 - val_loss: 0.0010\n",
      "Epoch 49/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 9.5008e-04\n",
      "Epoch 00049: val_loss improved from 0.00104 to 0.00103, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 9.4606e-04 - val_loss: 0.0010\n",
      "Epoch 50/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 9.4261e-04\n",
      "Epoch 00050: val_loss improved from 0.00103 to 0.00103, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 9.4310e-04 - val_loss: 0.0010\n",
      "Epoch 51/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 9.4394e-04\n",
      "Epoch 00051: val_loss improved from 0.00103 to 0.00102, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 9.4599e-04 - val_loss: 0.0010\n",
      "Epoch 52/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 9.4219e-04\n",
      "Epoch 00052: val_loss improved from 0.00102 to 0.00101, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 9.4012e-04 - val_loss: 0.0010\n",
      "Epoch 53/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 9.3477e-04\n",
      "Epoch 00053: val_loss improved from 0.00101 to 0.00101, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 2ms/sample - loss: 9.3269e-04 - val_loss: 0.0010\n",
      "Epoch 54/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 9.3545e-04\n",
      "Epoch 00054: val_loss improved from 0.00101 to 0.00101, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 9.3685e-04 - val_loss: 0.0010\n",
      "Epoch 55/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 9.3149e-04\n",
      "Epoch 00055: val_loss improved from 0.00101 to 0.00101, saving model to ../saved_models/autoencoder_cp.h5\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 9.2881e-04 - val_loss: 0.0010\n",
      "Epoch 56/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 9.2951e-04\n",
      "Epoch 00056: val_loss did not improve from 0.00101\n",
      "258/258 [==============================] - 0s 969us/sample - loss: 9.3119e-04 - val_loss: 0.0010\n",
      "Epoch 57/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 9.2833e-04\n",
      "Epoch 00057: val_loss did not improve from 0.00101\n",
      "258/258 [==============================] - 0s 953us/sample - loss: 9.2869e-04 - val_loss: 0.0010\n",
      "Epoch 58/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 9.2674e-04\n",
      "Epoch 00058: val_loss did not improve from 0.00101\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 9.2692e-04 - val_loss: 0.0010\n",
      "Epoch 59/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 9.2490e-04\n",
      "Epoch 00059: val_loss did not improve from 0.00101\n",
      "258/258 [==============================] - 0s 971us/sample - loss: 9.2303e-04 - val_loss: 0.0010\n",
      "Epoch 60/70\n",
      "192/258 [=====================>........] - ETA: 0s - loss: 9.2223e-04\n",
      "Epoch 00060: val_loss did not improve from 0.00101\n",
      "258/258 [==============================] - 0s 1ms/sample - loss: 9.2274e-04 - val_loss: 0.0010\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "checkpoint_path = r'../saved_models/autoencoder_cp.h5'\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                   monitor='val_loss',\n",
    "                                   save_best_only=True,\n",
    "                                   mode='min',\n",
    "                                   verbose=1)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                               mode='min',\n",
    "                               patience=5)\n",
    "\n",
    "callback_list = [model_checkpoint, early_stopping]\n",
    "\n",
    "auto_encode.compile(optimizer='Adam', loss='mse')\n",
    "history = auto_encode.fit(train, train, #train, train because targets of the autoencoder are the same as the input\n",
    "                          epochs = 70,\n",
    "                          batch_size = 64,\n",
    "                          shuffle = True,\n",
    "                          validation_data = (test, test),\n",
    "                          callbacks=callback_list,\n",
    "                          verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ebf50726",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_encode.save(r'../saved_models/auto_encode_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "753864a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = history.history[\"loss\"]\n",
    "test_loss = history.history['val_loss']\n",
    "epoch_labels = history.epoch\n",
    "\n",
    "losses = pd.DataFrame(data=list(zip(train_loss, test_loss)), columns=['train_loss', 'validation_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ae9f0669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.plot(train_loss, label='Training Loss', color='#185fad')\n",
    "plt.plot(test_loss, label='Testing Loss', color='orange')\n",
    "plt.title('Training and Testing Loss by Epoch', fontsize = 15)\n",
    "plt.xlabel('Epoch', fontsize = 10)\n",
    "plt.ylabel('MSE', fontsize = 10)\n",
    "plt.legend(fontsize = 10);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d85894c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = Model(auto_encode.inputs, auto_encode.get_layer('bottleneck').output)\n",
    "auto_encode_embedding = embedding.predict(tfidf_matrix_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "86b8bf20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: plum, berry, caturra, washed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Process</th>\n",
       "      <th>Variety</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Congo Kivu Kalehe Cooperative</td>\n",
       "      <td>Sweet, spiced and with tangy citrus accents, flavor notes of orange, cardamom pod and clove, marmalade spread, and the acidic impression is grabby like grapefruit. City to Full City.</td>\n",
       "      <td>Wet Washed</td>\n",
       "      <td>Bourbon</td>\n",
       "      <td>0.970039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Ethiopia Organic Nensebo Refisa</td>\n",
       "      <td>An aromatic cup in all of our roasts, dried florals, sweet herbs, and fragrant woody incense, notes of simple syrup, orange essence, fruit gum, and grabby citrus finish. City to Full City.</td>\n",
       "      <td>Wet Washed</td>\n",
       "      <td>Heirloom</td>\n",
       "      <td>0.958886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>Colombia Caicedo Las Alegrias</td>\n",
       "      <td>A cup with intimations of dried fruit against a backdrop of rustic, unrefined sugar sweetness, hints of dried raisin and plum, tea-like tannic acidity. Chocolatey dark roast. City to Full City+.</td>\n",
       "      <td>Wet Washed</td>\n",
       "      <td>Caturra, Typica, Modern Hybrids</td>\n",
       "      <td>0.958379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Kenya Embu Gakui Peaberry</td>\n",
       "      <td>Gakui's flavor profile is enlivened with fruit and spice notes like dried plum, date pieces, cinnamon stick, all spice powder, plum tea, tea-like tannic acidity, and some grapefruit bittering that...</td>\n",
       "      <td>Wet Washed</td>\n",
       "      <td>Bourbon</td>\n",
       "      <td>0.957957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>Colombia Urrao Fray Moreno</td>\n",
       "      <td>This coffee is anything but 'neutral'! Berry-toned aroma, stone fruit accent of red plum, hints of mint and Yerba Mate, and a tangy-sweet pomegranate note that heightens acidic impression. City to...</td>\n",
       "      <td>Wet Washed</td>\n",
       "      <td>Heirloom</td>\n",
       "      <td>0.957529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Name  \\\n",
       "16     Congo Kivu Kalehe Cooperative   \n",
       "46   Ethiopia Organic Nensebo Refisa   \n",
       "305    Colombia Caicedo Las Alegrias   \n",
       "57         Kenya Embu Gakui Peaberry   \n",
       "325       Colombia Urrao Fray Moreno   \n",
       "\n",
       "                                                                                                                                                                                                 Description  \\\n",
       "16                    Sweet, spiced and with tangy citrus accents, flavor notes of orange, cardamom pod and clove, marmalade spread, and the acidic impression is grabby like grapefruit. City to Full City.   \n",
       "46              An aromatic cup in all of our roasts, dried florals, sweet herbs, and fragrant woody incense, notes of simple syrup, orange essence, fruit gum, and grabby citrus finish. City to Full City.   \n",
       "305       A cup with intimations of dried fruit against a backdrop of rustic, unrefined sugar sweetness, hints of dried raisin and plum, tea-like tannic acidity. Chocolatey dark roast. City to Full City+.   \n",
       "57   Gakui's flavor profile is enlivened with fruit and spice notes like dried plum, date pieces, cinnamon stick, all spice powder, plum tea, tea-like tannic acidity, and some grapefruit bittering that...   \n",
       "325  This coffee is anything but 'neutral'! Berry-toned aroma, stone fruit accent of red plum, hints of mint and Yerba Mate, and a tangy-sweet pomegranate note that heightens acidic impression. City to...   \n",
       "\n",
       "        Process                          Variety  similarity_score  \n",
       "16   Wet Washed                          Bourbon          0.970039  \n",
       "46   Wet Washed                         Heirloom          0.958886  \n",
       "305  Wet Washed  Caturra, Typica, Modern Hybrids          0.958379  \n",
       "57   Wet Washed                          Bourbon          0.957957  \n",
       "325  Wet Washed                         Heirloom          0.957529  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_coffee_from_description_ae(query, auto_encode_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355eca53",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2083a84",
   "metadata": {},
   "source": [
    "Word2Vec is a popular word embedding technique used to learn the semantics of the words in a corpus. Like an auto-encoder, it encodes each word in a vector. However, instead of training the input words through the reconstruction process (encode/decode), Word2Vec trains words against those that are near to them in the vector space. It achieves this in two ways: continuous bag of words (CBOW) or skip-gram. I have chosen the latter for this project because it tends to perform better on smaller datasets and represents rare words well [Source](https://towardsdatascience.com/introduction-to-word-embedding-and-word2vec-652d0c2060fa).\n",
    "\n",
    "However, one key downside to note about Word2Vec is that it cannot produce vectors for words that were not in the original dataset used for training. While there are more advanced methods to deal with unseen data (such as Facebook's FastText which builds vectors from root words), I have decided to simply exclude any unseen words if they occur in the query sentence.\n",
    "\n",
    "For this project, I have chosen to train the model using Gensim's implementation of Word2Vec. These are the parameters I have adjusted for the model:\n",
    "- min_count = 0 (low since we are using a small dataset)\n",
    "- window = 2 (number of neighbouring words to affect the vector calculations)\n",
    "- vector_size = 100\n",
    "- alpha = 0.01 (learning rate)\n",
    "- min_alpha = 0.0007 (min value at which learning rate will decrease linearly)\n",
    "- sg = 1 (skip gram selected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c0e70265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_word_in_model(word, model):\n",
    "    \"\"\"Check if word is in the corpus from the trained model\"\"\"\n",
    "    assert type(model).__name__ == 'KeyedVectors'\n",
    "    is_in_vocab = word in model.key_to_index.keys()\n",
    "    return is_in_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "69552e36",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def recommend_coffee_from_description_w2v(query, dataset, model):\n",
    "    query = clean_text(query)\n",
    "    query = query.split(', ')\n",
    "    in_vocab_list = []\n",
    "    for w in query:\n",
    "        #Remove unseen words from query sentence\n",
    "        if is_word_in_model(w, model.wv):\n",
    "            in_vocab_list.append(w)\n",
    "\n",
    "    #Find similarity between query and dataset\n",
    "    if len(in_vocab_list) == 0:\n",
    "        print('Insufficient # of words in input')\n",
    "    else:\n",
    "        print(f'Query: {in_vocab_list}')\n",
    "        similarity_matrix = np.zeros(len(dataset))  \n",
    "        for i, data_sentence in enumerate(dataset):\n",
    "            if data_sentence:\n",
    "                similar_sentence = model.wv.n_similarity(\n",
    "                        in_vocab_list, data_sentence)\n",
    "            else:\n",
    "                similar_sentence = 0\n",
    "            similarity_matrix[i] = np.array(similar_sentence)\n",
    "    \n",
    "    similar_matrix = pd.DataFrame(similarity_matrix)\n",
    "    similar_items = pd.DataFrame(similar_matrix)\n",
    "    similar_items.columns = [\"similarity_score\"]\n",
    "    similar_items = similar_items.sort_values('similarity_score', ascending=False)\n",
    "    similar_items.reset_index(inplace=True)\n",
    "\n",
    "    #Use index as an 'item_id' \n",
    "    similar_items = similar_items.rename(index=str, columns={\"index\": \"item_id\"})\n",
    "    similar_coffees = pd.DataFrame(similar_items.to_dict())\n",
    "    similar_coffees.set_index('item_id', inplace=True)\n",
    "\n",
    "    #List top recommendations \n",
    "    similar_df = pd.merge(df_sweetmarias, similar_coffees, left_index=True, right_index=True)\n",
    "    similar_df.sort_values('similarity_score', ascending=False, inplace=True)\n",
    "    return similar_df[['Name','Description','Process','Variety','similarity_score']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "94d46f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class callback(CallbackAny2Vec):\n",
    "    '''Callback to print loss after each epoch.'''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "        self.loss_to_be_subed = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        loss = model.get_latest_training_loss()\n",
    "        loss_now = loss - self.loss_to_be_subed\n",
    "        self.loss_to_be_subed = loss\n",
    "        print('Loss after epoch {}: {}'.format(self.epoch, loss_now))\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a8228a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0: 69554.5\n",
      "Loss after epoch 1: 69525.03125\n",
      "Loss after epoch 2: 70263.640625\n",
      "Loss after epoch 3: 68208.421875\n",
      "Loss after epoch 4: 63497.6875\n",
      "Loss after epoch 5: 60539.875\n",
      "Loss after epoch 6: 56175.46875\n",
      "Loss after epoch 7: 53887.375\n",
      "Loss after epoch 8: 52866.625\n",
      "Loss after epoch 9: 51546.1875\n",
      "Loss after epoch 10: 50498.875\n",
      "Loss after epoch 11: 49089.625\n",
      "Loss after epoch 12: 49216.875\n",
      "Loss after epoch 13: 48179.8125\n",
      "Loss after epoch 14: 47111.375\n",
      "Loss after epoch 15: 47220.1875\n",
      "Loss after epoch 16: 46013.8125\n",
      "Loss after epoch 17: 44839.9375\n",
      "Loss after epoch 18: 44933.0625\n",
      "Loss after epoch 19: 44528.625\n",
      "Loss after epoch 20: 44349.75\n",
      "Loss after epoch 21: 44190.75\n",
      "Loss after epoch 22: 44112.875\n",
      "Loss after epoch 23: 43729.625\n",
      "Loss after epoch 24: 43426.25\n",
      "Loss after epoch 25: 43449.5\n",
      "Loss after epoch 26: 44499.125\n",
      "Loss after epoch 27: 43551.375\n",
      "Loss after epoch 28: 42950.0\n",
      "Loss after epoch 29: 43211.0\n",
      "Loss after epoch 30: 42683.125\n",
      "Loss after epoch 31: 42996.375\n",
      "Loss after epoch 32: 42592.375\n",
      "Loss after epoch 33: 42018.125\n",
      "Loss after epoch 34: 42491.25\n",
      "Loss after epoch 35: 41805.0\n",
      "Loss after epoch 36: 41796.0\n",
      "Loss after epoch 37: 42101.0\n",
      "Loss after epoch 38: 41767.875\n",
      "Loss after epoch 39: 41304.0\n",
      "Loss after epoch 40: 41475.625\n",
      "Loss after epoch 41: 41655.75\n",
      "Loss after epoch 42: 41278.875\n",
      "Loss after epoch 43: 41202.625\n",
      "Loss after epoch 44: 42108.75\n",
      "Loss after epoch 45: 41632.5\n",
      "Loss after epoch 46: 41472.75\n",
      "Loss after epoch 47: 41033.75\n",
      "Loss after epoch 48: 40942.75\n",
      "Loss after epoch 49: 40746.5\n",
      "Loss after epoch 50: 40549.5\n",
      "Loss after epoch 51: 40435.5\n",
      "Loss after epoch 52: 40483.5\n",
      "Loss after epoch 53: 39658.75\n",
      "Loss after epoch 54: 40304.25\n",
      "Loss after epoch 55: 39468.75\n",
      "Loss after epoch 56: 39582.75\n",
      "Loss after epoch 57: 39549.75\n",
      "Loss after epoch 58: 39759.5\n",
      "Loss after epoch 59: 39400.25\n",
      "Loss after epoch 60: 39318.5\n",
      "Loss after epoch 61: 39470.75\n",
      "Loss after epoch 62: 39297.75\n",
      "Loss after epoch 63: 38956.5\n",
      "Loss after epoch 64: 38739.0\n",
      "Loss after epoch 65: 38991.5\n",
      "Loss after epoch 66: 38465.5\n",
      "Loss after epoch 67: 39041.0\n",
      "Loss after epoch 68: 38510.25\n",
      "Loss after epoch 69: 38689.0\n",
      "Loss after epoch 70: 37971.0\n",
      "Loss after epoch 71: 38119.25\n",
      "Loss after epoch 72: 38234.5\n",
      "Loss after epoch 73: 37863.75\n",
      "Loss after epoch 74: 38365.75\n",
      "Loss after epoch 75: 37793.25\n",
      "Loss after epoch 76: 37994.0\n",
      "Loss after epoch 77: 38029.5\n",
      "Loss after epoch 78: 37080.0\n",
      "Loss after epoch 79: 37042.5\n",
      "Loss after epoch 80: 37204.5\n",
      "Loss after epoch 81: 36759.25\n",
      "Loss after epoch 82: 37307.25\n",
      "Loss after epoch 83: 37510.75\n",
      "Loss after epoch 84: 36825.25\n",
      "Loss after epoch 85: 37669.5\n",
      "Loss after epoch 86: 36657.25\n",
      "Loss after epoch 87: 36811.25\n",
      "Loss after epoch 88: 37760.75\n",
      "Loss after epoch 89: 37218.75\n",
      "Loss after epoch 90: 37000.75\n",
      "Loss after epoch 91: 36388.5\n",
      "Loss after epoch 92: 36284.75\n",
      "Loss after epoch 93: 36892.75\n",
      "Loss after epoch 94: 36733.5\n",
      "Loss after epoch 95: 36731.0\n",
      "Loss after epoch 96: 36592.0\n",
      "Loss after epoch 97: 36567.0\n",
      "Loss after epoch 98: 31828.25\n",
      "Loss after epoch 99: 31533.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(595740, 938800)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model = Word2Vec(min_count=0,\n",
    "                     window=2,\n",
    "                     vector_size=100, \n",
    "                     alpha=0.01, \n",
    "                     min_alpha=0.0007, \n",
    "                     sg = 1) \n",
    "\n",
    "w2v_model.build_vocab(df_sweetmarias['tok_lem_combined'].values)\n",
    "w2v_model.train(df_sweetmarias['tok_lem_combined'].values, total_examples=w2v_model.corpus_count, epochs=100, callbacks=[callback()],\n",
    "                         compute_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "de4ac206",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.save(r'../saved_models/word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0e58133a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: ['plum', 'berry', 'caturra', 'washed']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Process</th>\n",
       "      <th>Variety</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>Colombia Inzá Rio Paez</td>\n",
       "      <td>The fruited side of Rio Paez emerges as it cools, hints of cherry, cooked apple and a winey plum note. Pour overs are profusely sweet, with a tea-like aftertaste and tannic bittering in mouthfeel....</td>\n",
       "      <td>Wet Washed</td>\n",
       "      <td>Caturra, Typica, Modern Hybrids</td>\n",
       "      <td>0.937422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>Guatemala Patzun Finca Las Camelias</td>\n",
       "      <td>Fruit flavors are most front-facing at Full City, blackberry and red raisin rolled into dense layers of dark chocolate, and Dutch drinking cocoa, accents of torched sugar glaze. Full City to Full ...</td>\n",
       "      <td>Wet Washed</td>\n",
       "      <td>Caturra, Bourbon, Modern Hybrids</td>\n",
       "      <td>0.931425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>Colombia Buesaco Alianza Granjeros</td>\n",
       "      <td>A caramel-sweet overtone, aromatic butterscotch note, hints of apple, dried date and an herbal accent in the aftertaste. Acidic impression like brisk black tea when roasted light. City to Full Cit...</td>\n",
       "      <td>Wet Washed</td>\n",
       "      <td>Caturra, Bourbon, Typica, Modern Hybrids</td>\n",
       "      <td>0.929653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Peru Nuevo Trujillo Marcial Olivera</td>\n",
       "      <td>One of our brighter Peru's, City roasts produce a bright acidic impression, fruit hints of black currant and red apple, opaque date sugar sweetness and hints of tree nut. City to Full City+. Good ...</td>\n",
       "      <td>Wet Washed</td>\n",
       "      <td>Caturra, Bourbon, Typica, Modern Hybrids</td>\n",
       "      <td>0.929286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Guatemala Xinabajul Evelio Villatoro</td>\n",
       "      <td>Complex as it cools, underlying flavors are fruited with caramelized sugars, accents of brisk tea, cardamom, and a berry note that feeds into a blueberry-like acidic impression. Delicious! City to...</td>\n",
       "      <td>Wet Washed</td>\n",
       "      <td>Caturra, Bourbon, Typica, Modern Hybrids</td>\n",
       "      <td>0.928712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Name  \\\n",
       "314                Colombia Inzá Rio Paez   \n",
       "183   Guatemala Patzun Finca Las Camelias   \n",
       "303    Colombia Buesaco Alianza Granjeros   \n",
       "340   Peru Nuevo Trujillo Marcial Olivera   \n",
       "190  Guatemala Xinabajul Evelio Villatoro   \n",
       "\n",
       "                                                                                                                                                                                                 Description  \\\n",
       "314  The fruited side of Rio Paez emerges as it cools, hints of cherry, cooked apple and a winey plum note. Pour overs are profusely sweet, with a tea-like aftertaste and tannic bittering in mouthfeel....   \n",
       "183  Fruit flavors are most front-facing at Full City, blackberry and red raisin rolled into dense layers of dark chocolate, and Dutch drinking cocoa, accents of torched sugar glaze. Full City to Full ...   \n",
       "303  A caramel-sweet overtone, aromatic butterscotch note, hints of apple, dried date and an herbal accent in the aftertaste. Acidic impression like brisk black tea when roasted light. City to Full Cit...   \n",
       "340  One of our brighter Peru's, City roasts produce a bright acidic impression, fruit hints of black currant and red apple, opaque date sugar sweetness and hints of tree nut. City to Full City+. Good ...   \n",
       "190  Complex as it cools, underlying flavors are fruited with caramelized sugars, accents of brisk tea, cardamom, and a berry note that feeds into a blueberry-like acidic impression. Delicious! City to...   \n",
       "\n",
       "        Process                                   Variety  similarity_score  \n",
       "314  Wet Washed           Caturra, Typica, Modern Hybrids          0.937422  \n",
       "183  Wet Washed          Caturra, Bourbon, Modern Hybrids          0.931425  \n",
       "303  Wet Washed  Caturra, Bourbon, Typica, Modern Hybrids          0.929653  \n",
       "340  Wet Washed  Caturra, Bourbon, Typica, Modern Hybrids          0.929286  \n",
       "190  Wet Washed  Caturra, Bourbon, Typica, Modern Hybrids          0.928712  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_coffee_from_description_w2v(query, df_sweetmarias['tok_lem_combined'].values, w2v_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3836718",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db50f1b4",
   "metadata": {},
   "source": [
    "BERT is a langugage model that represents one of the most recent advances in NLP. It is a bi-directional transformer pre-trained useing both masked language modelling (MLM) and next sentence prediction (NSL) on a large corpus comprising of BookCorpus and Wikipedia. Compared to Word2Vec, what makes transformers such as BERT more powerful is the ability to encode context of a given word from preceding and succeeding words in the vector via its *attention mechanism*. This attention mechanism allows us to look at the totality of the a sentence and make connections between words and its relevant context - this is markedly different from and more complext than the simple feed-forward auto-encoder which I have built above as that treats each word as an input independent of each other. \n",
    "\n",
    "For this project, I have chosen to use a direct implementation of the BERT architecture from SentenceTransformers. More specifically, I have selected the *paraphrase-MiniLM-L6-v2* model from SentenceTransformers as it performs relatively fast and is pre-trained specifically for tasks such as clustering or semantic search (more details [here](https://huggingface.co/sentence-transformers/paraphrase-MiniLM-L6-v2)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c978c7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_coffee_from_description_bert(query, corpus_embeddings):\n",
    "    \n",
    "    set_seed(42)\n",
    "    \n",
    "    #Embed query\n",
    "    clean_query = clean_text(query)\n",
    "    query_embedding = BERT_model.encode(query, convert_to_tensor=True)\n",
    "    \n",
    "    print(f'Query: {clean_query}')\n",
    "    \n",
    "    #Matrix of similarity between query and database\n",
    "    cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "    similarity_matrix = pd.DataFrame(cos_scores)\n",
    "    \n",
    "    #New column of 'similarity_score'\n",
    "    similar_items = pd.DataFrame(similarity_matrix)\n",
    "    similar_items.columns = [\"similarity_score\"]\n",
    "    similar_items = similar_items.sort_values('similarity_score', ascending=False)\n",
    "    similar_items.reset_index(inplace=True)\n",
    "    \n",
    "    #Use index as an 'item_id' \n",
    "    similar_items = similar_items.rename(index=str, columns={\"index\": \"item_id\"})\n",
    "    similar_coffees = pd.DataFrame(similar_items.to_dict())\n",
    "    similar_coffees.set_index('item_id', inplace=True)\n",
    "    \n",
    "    #List top recommendations \n",
    "    similar_df = pd.merge(df_sweetmarias, similar_coffees, left_index=True, right_index=True)\n",
    "    similar_df.sort_values('similarity_score', ascending=False, inplace=True)\n",
    "    return similar_df[['Name','Description','Process','Variety','similarity_score']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3d542f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "BERT_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "corpus_embeddings = BERT_model.encode(df_sweetmarias['cleaned_combined'].values, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8d6513f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: plum, berry, caturra, washed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Process</th>\n",
       "      <th>Variety</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>Colombia Inzá Rio Paez</td>\n",
       "      <td>The fruited side of Rio Paez emerges as it cools, hints of cherry, cooked apple and a winey plum note. Pour overs are profusely sweet, with a tea-like aftertaste and tannic bittering in mouthfeel....</td>\n",
       "      <td>Wet Washed</td>\n",
       "      <td>Caturra, Typica, Modern Hybrids</td>\n",
       "      <td>0.602068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>Colombia Urrao Fray Moreno</td>\n",
       "      <td>This coffee is anything but 'neutral'! Berry-toned aroma, stone fruit accent of red plum, hints of mint and Yerba Mate, and a tangy-sweet pomegranate note that heightens acidic impression. City to...</td>\n",
       "      <td>Wet Washed</td>\n",
       "      <td>Heirloom</td>\n",
       "      <td>0.578095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Ethiopia Organic Shakiso Kayon Mountain Farm</td>\n",
       "      <td>Unrefined sugar sweetness is cut through by a rindy citrus flavor, fruited accent notes of orange and dried strawberry, aromatic herbals, Earl Grey and hibiscus teas, and a soft floral jasmine not...</td>\n",
       "      <td>Wet Washed</td>\n",
       "      <td>Heirloom</td>\n",
       "      <td>0.574332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Ethiopia Guji Hambela Dabaye</td>\n",
       "      <td>Impressive sweetness, demurara sugar, cream soda, mild fruited accents of nectarine and lemon, and a touch of clove in aroma. Peach-like acidity helps build out the fruited impressions. City to Fu...</td>\n",
       "      <td>Wet Washed</td>\n",
       "      <td>Heirloom</td>\n",
       "      <td>0.568525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Kenya Nyeri Kamoini Peaberry</td>\n",
       "      <td>Bodied, a plump blackberry note, fruits cooked with brown sugar like pineapple upside down cake, accents of clove and nutmeg, and blueberry acidic impression. City to Full City. Good for espresso.</td>\n",
       "      <td>Wet Washed</td>\n",
       "      <td>Bourbon</td>\n",
       "      <td>0.565445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Name  \\\n",
       "314                        Colombia Inzá Rio Paez   \n",
       "325                    Colombia Urrao Fray Moreno   \n",
       "47   Ethiopia Organic Shakiso Kayon Mountain Farm   \n",
       "39                   Ethiopia Guji Hambela Dabaye   \n",
       "92                   Kenya Nyeri Kamoini Peaberry   \n",
       "\n",
       "                                                                                                                                                                                                 Description  \\\n",
       "314  The fruited side of Rio Paez emerges as it cools, hints of cherry, cooked apple and a winey plum note. Pour overs are profusely sweet, with a tea-like aftertaste and tannic bittering in mouthfeel....   \n",
       "325  This coffee is anything but 'neutral'! Berry-toned aroma, stone fruit accent of red plum, hints of mint and Yerba Mate, and a tangy-sweet pomegranate note that heightens acidic impression. City to...   \n",
       "47   Unrefined sugar sweetness is cut through by a rindy citrus flavor, fruited accent notes of orange and dried strawberry, aromatic herbals, Earl Grey and hibiscus teas, and a soft floral jasmine not...   \n",
       "39   Impressive sweetness, demurara sugar, cream soda, mild fruited accents of nectarine and lemon, and a touch of clove in aroma. Peach-like acidity helps build out the fruited impressions. City to Fu...   \n",
       "92      Bodied, a plump blackberry note, fruits cooked with brown sugar like pineapple upside down cake, accents of clove and nutmeg, and blueberry acidic impression. City to Full City. Good for espresso.   \n",
       "\n",
       "        Process                          Variety  similarity_score  \n",
       "314  Wet Washed  Caturra, Typica, Modern Hybrids          0.602068  \n",
       "325  Wet Washed                         Heirloom          0.578095  \n",
       "47   Wet Washed                         Heirloom          0.574332  \n",
       "39   Wet Washed                         Heirloom          0.568525  \n",
       "92   Wet Washed                          Bourbon          0.565445  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_coffee_from_description_bert(query, corpus_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c651fbcc",
   "metadata": {},
   "source": [
    "# Model Comparison with OCR Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09243e89",
   "metadata": {},
   "source": [
    "I will now compare the 4 models with an input from the OCR tool. Results are analysed in detail below.\n",
    "\n",
    "Overall, I would think that the TF-IDF model satisifes the main aims of the recommender system purely because the input from the OCR tool are single words. Instead of typical search query that has semantic meaning (e.g. 'I am looking for a washed processed Tanzanian coffee with notes of molasses and friar plums'), the OCR tool has distilled the query into keywords with little or not semantic structure. As such, TF-IDF actually produced good results, even though it is considered less complex than the state-of-the-art BERT model.\n",
    "\n",
    "However, in future developments, an advanced model is probably more fit for purpose. For example, recognising the difference between 'honey taste' and 'honey processing method' will probably need a BERT model to analyse context. The three other models in this project do not have that ability to make such contextual references since they are uni-directional (BERT is a bi-directional transformer). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "614bf4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr = pd.read_csv(r'../data/consolidated_all_images_70pct_0811_vfinal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b710d022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'even, not, coffee, roaster, washed, tanzania, molasses, plum, friar'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = ocr['final_text'][9]\n",
    "query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a6b20d",
   "metadata": {},
   "source": [
    "**TF-IDF**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07893841",
   "metadata": {},
   "source": [
    "Decent results: both 'molasses' and 'plum'  appear in the top 4 recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e5ab3226",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: washed, tanzania, molasses, plum, friar\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Process</th>\n",
       "      <th>Variety</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>Colombia Tolima Productores de Ibagué</td>\n",
       "      <td>Unrefined sugar sweetness is central to the cup, accented by top notes of oatmeal cookie, molasses, dried date and cola nut, with plum-like acidity. City+ to Full City+.</td>\n",
       "      <td>Wet Washed</td>\n",
       "      <td>Caturra, Bourbon, Modern Hybrids</td>\n",
       "      <td>0.329559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>Colombia Ibagué Rio Combeima</td>\n",
       "      <td>Delicious in the light to middle roasts, panela and molasses sweetness, winey apple and plum hints, a cinnamon note, tannic black tea and cranberry-like acidic impression. City to City+.</td>\n",
       "      <td>Wet Washed</td>\n",
       "      <td>Caturra, Bourbon, Typica, Modern Hybrids</td>\n",
       "      <td>0.309904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Rwanda Dry Process Nyakabingo</td>\n",
       "      <td>Middle roasts move beyond molasses sweetness, to fruit and spice flavors, notes of berry-infused dark chocolate, plum, overripe citrus, and a hint of heart of palm in the finish. City+ to Full City.</td>\n",
       "      <td>Dry Natural</td>\n",
       "      <td>Bourbon</td>\n",
       "      <td>0.298306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>Colombia Urrao Valle de Penderisco</td>\n",
       "      <td>Molasses, demurara sugar, moderate brightness, accents of berry and hibiscus flower tea. Dark roasts boast heavy-handed cocoa roast flavors and plum. City+ to Full City+. Good for espresso.</td>\n",
       "      <td>Wet Washed</td>\n",
       "      <td>Caturra, Bourbon, Heirloom</td>\n",
       "      <td>0.290191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>Colombia Caicedo Las Alegrias</td>\n",
       "      <td>A cup with intimations of dried fruit against a backdrop of rustic, unrefined sugar sweetness, hints of dried raisin and plum, tea-like tannic acidity. Chocolatey dark roast. City to Full City+.</td>\n",
       "      <td>Wet Washed</td>\n",
       "      <td>Caturra, Typica, Modern Hybrids</td>\n",
       "      <td>0.196123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Name  \\\n",
       "323  Colombia Tolima Productores de Ibagué   \n",
       "309           Colombia Ibagué Rio Combeima   \n",
       "105          Rwanda Dry Process Nyakabingo   \n",
       "328     Colombia Urrao Valle de Penderisco   \n",
       "305          Colombia Caicedo Las Alegrias   \n",
       "\n",
       "                                                                                                                                                                                                Description  \\\n",
       "323                               Unrefined sugar sweetness is central to the cup, accented by top notes of oatmeal cookie, molasses, dried date and cola nut, with plum-like acidity. City+ to Full City+.   \n",
       "309              Delicious in the light to middle roasts, panela and molasses sweetness, winey apple and plum hints, a cinnamon note, tannic black tea and cranberry-like acidic impression. City to City+.   \n",
       "105  Middle roasts move beyond molasses sweetness, to fruit and spice flavors, notes of berry-infused dark chocolate, plum, overripe citrus, and a hint of heart of palm in the finish. City+ to Full City.   \n",
       "328           Molasses, demurara sugar, moderate brightness, accents of berry and hibiscus flower tea. Dark roasts boast heavy-handed cocoa roast flavors and plum. City+ to Full City+. Good for espresso.   \n",
       "305      A cup with intimations of dried fruit against a backdrop of rustic, unrefined sugar sweetness, hints of dried raisin and plum, tea-like tannic acidity. Chocolatey dark roast. City to Full City+.   \n",
       "\n",
       "         Process                                   Variety  similarity_score  \n",
       "323   Wet Washed          Caturra, Bourbon, Modern Hybrids          0.329559  \n",
       "309   Wet Washed  Caturra, Bourbon, Typica, Modern Hybrids          0.309904  \n",
       "105  Dry Natural                                   Bourbon          0.298306  \n",
       "328   Wet Washed                Caturra, Bourbon, Heirloom          0.290191  \n",
       "305   Wet Washed           Caturra, Typica, Modern Hybrids          0.196123  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_coffee_from_description_tfidf(query, tfidf_matrix_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a0f235",
   "metadata": {},
   "source": [
    "**Auto-Encoder**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5c426e",
   "metadata": {},
   "source": [
    "Results from our auto-encoder are fair - it maanged to pick up a few coffees with 'plum' key words, but nothing on 'molasses'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f0988bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: washed, tanzania, molasses, plum, friar\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Process</th>\n",
       "      <th>Variety</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Kenya Embu Gakui Peaberry</td>\n",
       "      <td>Gakui's flavor profile is enlivened with fruit and spice notes like dried plum, date pieces, cinnamon stick, all spice powder, plum tea, tea-like tannic acidity, and some grapefruit bittering that...</td>\n",
       "      <td>Wet Washed</td>\n",
       "      <td>Bourbon</td>\n",
       "      <td>0.956376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>Colombia Caicedo Las Alegrias</td>\n",
       "      <td>A cup with intimations of dried fruit against a backdrop of rustic, unrefined sugar sweetness, hints of dried raisin and plum, tea-like tannic acidity. Chocolatey dark roast. City to Full City+.</td>\n",
       "      <td>Wet Washed</td>\n",
       "      <td>Caturra, Typica, Modern Hybrids</td>\n",
       "      <td>0.952937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Rwanda Nyamasheke Gatare Peaberry</td>\n",
       "      <td>Aspects of semi-refined sugars, fruited acidity, laced with hints of warming spice, orange tea, and dried apple. Deep chocolate roast flavors with darker roast develoment. City to Full City+. Good...</td>\n",
       "      <td>Wet Washed</td>\n",
       "      <td>Bourbon</td>\n",
       "      <td>0.950206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Guatemala Huehuetenango Finca Rosma</td>\n",
       "      <td>A flavor compound of oatmeal-raisin cookie, molasses sugar, rustic dark fruit, cacao bittersweetness, dried coconut, and berry-like acidity. City+ to Full City+. Good for espresso.</td>\n",
       "      <td>Wet Washed</td>\n",
       "      <td>Caturra, Bourbon, Typica, Modern Hybrids</td>\n",
       "      <td>0.949646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Kenya Muranga Kangunu Peaberry</td>\n",
       "      <td>Sweet at its core, Kangunu peaberry offers an array of fruited accent notes, such as plump cranberry, holiday fruit punch, bergamot citrus, tangy plum tea and tamarind. Finish is so aromatic. City...</td>\n",
       "      <td>Wet Washed</td>\n",
       "      <td>Bourbon</td>\n",
       "      <td>0.949599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Name  \\\n",
       "57             Kenya Embu Gakui Peaberry   \n",
       "305        Colombia Caicedo Las Alegrias   \n",
       "110    Rwanda Nyamasheke Gatare Peaberry   \n",
       "175  Guatemala Huehuetenango Finca Rosma   \n",
       "76        Kenya Muranga Kangunu Peaberry   \n",
       "\n",
       "                                                                                                                                                                                                 Description  \\\n",
       "57   Gakui's flavor profile is enlivened with fruit and spice notes like dried plum, date pieces, cinnamon stick, all spice powder, plum tea, tea-like tannic acidity, and some grapefruit bittering that...   \n",
       "305       A cup with intimations of dried fruit against a backdrop of rustic, unrefined sugar sweetness, hints of dried raisin and plum, tea-like tannic acidity. Chocolatey dark roast. City to Full City+.   \n",
       "110  Aspects of semi-refined sugars, fruited acidity, laced with hints of warming spice, orange tea, and dried apple. Deep chocolate roast flavors with darker roast develoment. City to Full City+. Good...   \n",
       "175                     A flavor compound of oatmeal-raisin cookie, molasses sugar, rustic dark fruit, cacao bittersweetness, dried coconut, and berry-like acidity. City+ to Full City+. Good for espresso.   \n",
       "76   Sweet at its core, Kangunu peaberry offers an array of fruited accent notes, such as plump cranberry, holiday fruit punch, bergamot citrus, tangy plum tea and tamarind. Finish is so aromatic. City...   \n",
       "\n",
       "        Process                                   Variety  similarity_score  \n",
       "57   Wet Washed                                   Bourbon          0.956376  \n",
       "305  Wet Washed           Caturra, Typica, Modern Hybrids          0.952937  \n",
       "110  Wet Washed                                   Bourbon          0.950206  \n",
       "175  Wet Washed  Caturra, Bourbon, Typica, Modern Hybrids          0.949646  \n",
       "76   Wet Washed                                   Bourbon          0.949599  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_coffee_from_description_ae(query, auto_encode_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a0ab5f",
   "metadata": {},
   "source": [
    "**Word2Vec**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83e13a3",
   "metadata": {},
   "source": [
    "For Word2Vec, we only have 3 query keywords. The words 'Tanzania' and 'friar' have been dropped because they are not in the vocabulary of the corpus that we trained on - this is one of the key advantage of Word2Vec which was mentioned earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "974dd1d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: ['washed', 'molasses', 'plum']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Process</th>\n",
       "      <th>Variety</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Kenya Embu Gakui Peaberry</td>\n",
       "      <td>Gakui's flavor profile is enlivened with fruit and spice notes like dried plum, date pieces, cinnamon stick, all spice powder, plum tea, tea-like tannic acidity, and some grapefruit bittering that...</td>\n",
       "      <td>Wet Washed</td>\n",
       "      <td>Bourbon</td>\n",
       "      <td>0.940001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>Colombia Caicedo Las Alegrias</td>\n",
       "      <td>A cup with intimations of dried fruit against a backdrop of rustic, unrefined sugar sweetness, hints of dried raisin and plum, tea-like tannic acidity. Chocolatey dark roast. City to Full City+.</td>\n",
       "      <td>Wet Washed</td>\n",
       "      <td>Caturra, Typica, Modern Hybrids</td>\n",
       "      <td>0.928197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Kenya Nyeri Kiruga AB</td>\n",
       "      <td>Depth of sweetness (scoring 9.5!), raw sugars, fruit jam hints, fig, dried berry and a spiced grape juice note as it cools. Moderate brightness and capable of berry-laden cocoa when roasted dark. ...</td>\n",
       "      <td>Wet Washed</td>\n",
       "      <td>Bourbon</td>\n",
       "      <td>0.927735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Kenya Kiambu Fram Farm Peaberry</td>\n",
       "      <td>Fruit and brown sugar sweetness are intense, accents of grape, fresh date, fig, blackberry crumble, a woody incense aromatic note, and well-integrated, berry-like acidity. City+ to Full City.</td>\n",
       "      <td>Wet Washed</td>\n",
       "      <td>Bourbon</td>\n",
       "      <td>0.926772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Tanzania Nogorongoro Karatu Peaberry</td>\n",
       "      <td>A tasty confluence of moderate fruit and sweetness, and relatively high acidity lends structure to notes of palm sugar, berry tea, ripe black plum, a lemongrass note, and tannic bittering in the b...</td>\n",
       "      <td>Wet Washed</td>\n",
       "      <td>Bourbon, Modern Hybrids</td>\n",
       "      <td>0.925983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Name  \\\n",
       "57              Kenya Embu Gakui Peaberry   \n",
       "305         Colombia Caicedo Las Alegrias   \n",
       "95                  Kenya Nyeri Kiruga AB   \n",
       "65        Kenya Kiambu Fram Farm Peaberry   \n",
       "120  Tanzania Nogorongoro Karatu Peaberry   \n",
       "\n",
       "                                                                                                                                                                                                 Description  \\\n",
       "57   Gakui's flavor profile is enlivened with fruit and spice notes like dried plum, date pieces, cinnamon stick, all spice powder, plum tea, tea-like tannic acidity, and some grapefruit bittering that...   \n",
       "305       A cup with intimations of dried fruit against a backdrop of rustic, unrefined sugar sweetness, hints of dried raisin and plum, tea-like tannic acidity. Chocolatey dark roast. City to Full City+.   \n",
       "95   Depth of sweetness (scoring 9.5!), raw sugars, fruit jam hints, fig, dried berry and a spiced grape juice note as it cools. Moderate brightness and capable of berry-laden cocoa when roasted dark. ...   \n",
       "65           Fruit and brown sugar sweetness are intense, accents of grape, fresh date, fig, blackberry crumble, a woody incense aromatic note, and well-integrated, berry-like acidity. City+ to Full City.   \n",
       "120  A tasty confluence of moderate fruit and sweetness, and relatively high acidity lends structure to notes of palm sugar, berry tea, ripe black plum, a lemongrass note, and tannic bittering in the b...   \n",
       "\n",
       "        Process                          Variety  similarity_score  \n",
       "57   Wet Washed                          Bourbon          0.940001  \n",
       "305  Wet Washed  Caturra, Typica, Modern Hybrids          0.928197  \n",
       "95   Wet Washed                          Bourbon          0.927735  \n",
       "65   Wet Washed                          Bourbon          0.926772  \n",
       "120  Wet Washed          Bourbon, Modern Hybrids          0.925983  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_coffee_from_description_w2v(query, df_sweetmarias['tok_lem_combined'].values, w2v_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55408fa4",
   "metadata": {},
   "source": [
    "**BERT**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ab3661",
   "metadata": {},
   "source": [
    "Bert, which was trained on Wikipedia and BookCorpus, have associated Tanzania as a country and selected coffees with country names appearing in the description (e.g. Kenya, Guatemala, Burundi). In addition, it was also able to associate 'molasses' with 'sweetness' ('molasses sweetness' appear 4 times in the corpus), and have generated coffee descriptions with 'sweetness' in them. However, it is important to note that the key words such as 'molasses' and 'plum' do not show up in most of the top 5 recommendations.\n",
    "\n",
    "When the word 'Tanzania' is removed, results are a lot better as the country 'Tazania' was probably unduly affecting the BERT results by recommending coffees whose descriptions have a country word in them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409ec85c",
   "metadata": {},
   "source": [
    "*With 'Tanzania'*  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5d7245bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: washed, tanzania, molasses, plum, friar\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Process</th>\n",
       "      <th>Variety</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Burundi Commune Mutambu</td>\n",
       "      <td>Such a versatile Burundi, a neutral sweetness is accented by complex baking spices, creamed honey, loose leaf black tea and bittering cocoa when roasted dark. City to Full City+. Good for espresso.</td>\n",
       "      <td>Wet Washed</td>\n",
       "      <td>Bourbon</td>\n",
       "      <td>0.712786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Guatemala Proyecto Xinabajul Donaldo Villatoro</td>\n",
       "      <td>An aromatic Guatemalan coffee with brisk acidity, toasted sugar sweetness, and flavor notes of warming spices, Earl Grey tea, dried plum and milk chocolate. City to Full City.</td>\n",
       "      <td>Wet Washed</td>\n",
       "      <td>Caturra, Bourbon, Typica</td>\n",
       "      <td>0.696692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>Colombia Urrao Valle de Penderisco</td>\n",
       "      <td>Molasses, demurara sugar, moderate brightness, accents of berry and hibiscus flower tea. Dark roasts boast heavy-handed cocoa roast flavors and plum. City+ to Full City+. Good for espresso.</td>\n",
       "      <td>Wet Washed</td>\n",
       "      <td>Caturra, Bourbon, Heirloom</td>\n",
       "      <td>0.693887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Cameroon Caplami Java Cultivar</td>\n",
       "      <td>An interesting, thick bodied cup, notes of caramel and molasses, cinnamon, pipe tobacco, powdered orange drink, malted grains, aromatic woody dimension. City++ to Full City+.</td>\n",
       "      <td>Wet Washed</td>\n",
       "      <td>Heirloom</td>\n",
       "      <td>0.690076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>El Salvador Matalapa Mirador</td>\n",
       "      <td>Middle roasts are bodied, notes of hazelnut spread, milk chocolate, honey on toast, fruited cacao, Brazil nut, finishing with some tea tannins in mouthfeel. City+ to Full City+. Good for espresso.</td>\n",
       "      <td>Wet Washed</td>\n",
       "      <td>Bourbon</td>\n",
       "      <td>0.687154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Name  \\\n",
       "0                           Burundi Commune Mutambu   \n",
       "186  Guatemala Proyecto Xinabajul Donaldo Villatoro   \n",
       "328              Colombia Urrao Valle de Penderisco   \n",
       "15                   Cameroon Caplami Java Cultivar   \n",
       "150                    El Salvador Matalapa Mirador   \n",
       "\n",
       "                                                                                                                                                                                               Description  \\\n",
       "0    Such a versatile Burundi, a neutral sweetness is accented by complex baking spices, creamed honey, loose leaf black tea and bittering cocoa when roasted dark. City to Full City+. Good for espresso.   \n",
       "186                        An aromatic Guatemalan coffee with brisk acidity, toasted sugar sweetness, and flavor notes of warming spices, Earl Grey tea, dried plum and milk chocolate. City to Full City.   \n",
       "328          Molasses, demurara sugar, moderate brightness, accents of berry and hibiscus flower tea. Dark roasts boast heavy-handed cocoa roast flavors and plum. City+ to Full City+. Good for espresso.   \n",
       "15                          An interesting, thick bodied cup, notes of caramel and molasses, cinnamon, pipe tobacco, powdered orange drink, malted grains, aromatic woody dimension. City++ to Full City+.   \n",
       "150   Middle roasts are bodied, notes of hazelnut spread, milk chocolate, honey on toast, fruited cacao, Brazil nut, finishing with some tea tannins in mouthfeel. City+ to Full City+. Good for espresso.   \n",
       "\n",
       "        Process                     Variety  similarity_score  \n",
       "0    Wet Washed                     Bourbon          0.712786  \n",
       "186  Wet Washed    Caturra, Bourbon, Typica          0.696692  \n",
       "328  Wet Washed  Caturra, Bourbon, Heirloom          0.693887  \n",
       "15   Wet Washed                    Heirloom          0.690076  \n",
       "150  Wet Washed                     Bourbon          0.687154  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_coffee_from_description_bert(query, corpus_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07416b24",
   "metadata": {},
   "source": [
    "*Without 'Tanzania'*  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5920a489",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_revised = 'washed, molasses, plum, friar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c6c9cfe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: washed, molasses, plum, friar\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Process</th>\n",
       "      <th>Variety</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>Colombia Urrao Valle de Penderisco</td>\n",
       "      <td>Molasses, demurara sugar, moderate brightness, accents of berry and hibiscus flower tea. Dark roasts boast heavy-handed cocoa roast flavors and plum. City+ to Full City+. Good for espresso.</td>\n",
       "      <td>Wet Washed</td>\n",
       "      <td>Caturra, Bourbon, Heirloom</td>\n",
       "      <td>0.557297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Cameroon Caplami Java Cultivar</td>\n",
       "      <td>An interesting, thick bodied cup, notes of caramel and molasses, cinnamon, pipe tobacco, powdered orange drink, malted grains, aromatic woody dimension. City++ to Full City+.</td>\n",
       "      <td>Wet Washed</td>\n",
       "      <td>Heirloom</td>\n",
       "      <td>0.548952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Burundi Rwiri Yagikawa</td>\n",
       "      <td>A medium-bodied coffee with silky mouthfeel, turbinado sweetness, opening up to hints of chamomile and roasted barley teas, clove powder, and a subtle whiff of orange in the nose. City to Full City.</td>\n",
       "      <td>Wet Washed</td>\n",
       "      <td>Bourbon</td>\n",
       "      <td>0.542813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>Mexico Chiapas Cerro Brujo Don Sergio</td>\n",
       "      <td>A 'complete' cup with regard to developed sweetness and subtle top notes, brown sugar flavors, molasses aroma, subtle hint of orange and dried fruit that don't detract from core sweetness. City+ t...</td>\n",
       "      <td>Wet Washed</td>\n",
       "      <td></td>\n",
       "      <td>0.511689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Ethiopia Sidama Shentabene Chire</td>\n",
       "      <td>This Sidama makes for a delicate, refined pour over, perfumed pearl jasmine and rose water aroma, simple syrup sweetness, and hints of red apple, Botan rice candies, and black tea. City to City+.</td>\n",
       "      <td>Wet Washed</td>\n",
       "      <td>Heirloom</td>\n",
       "      <td>0.511194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Name  \\\n",
       "328     Colombia Urrao Valle de Penderisco   \n",
       "15          Cameroon Caplami Java Cultivar   \n",
       "12                  Burundi Rwiri Yagikawa   \n",
       "207  Mexico Chiapas Cerro Brujo Don Sergio   \n",
       "49        Ethiopia Sidama Shentabene Chire   \n",
       "\n",
       "                                                                                                                                                                                                 Description  \\\n",
       "328            Molasses, demurara sugar, moderate brightness, accents of berry and hibiscus flower tea. Dark roasts boast heavy-handed cocoa roast flavors and plum. City+ to Full City+. Good for espresso.   \n",
       "15                            An interesting, thick bodied cup, notes of caramel and molasses, cinnamon, pipe tobacco, powdered orange drink, malted grains, aromatic woody dimension. City++ to Full City+.   \n",
       "12    A medium-bodied coffee with silky mouthfeel, turbinado sweetness, opening up to hints of chamomile and roasted barley teas, clove powder, and a subtle whiff of orange in the nose. City to Full City.   \n",
       "207  A 'complete' cup with regard to developed sweetness and subtle top notes, brown sugar flavors, molasses aroma, subtle hint of orange and dried fruit that don't detract from core sweetness. City+ t...   \n",
       "49       This Sidama makes for a delicate, refined pour over, perfumed pearl jasmine and rose water aroma, simple syrup sweetness, and hints of red apple, Botan rice candies, and black tea. City to City+.   \n",
       "\n",
       "        Process                     Variety  similarity_score  \n",
       "328  Wet Washed  Caturra, Bourbon, Heirloom          0.557297  \n",
       "15   Wet Washed                    Heirloom          0.548952  \n",
       "12   Wet Washed                     Bourbon          0.542813  \n",
       "207  Wet Washed                                      0.511689  \n",
       "49   Wet Washed                    Heirloom          0.511194  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_coffee_from_description_bert(query_revised, corpus_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333c7fd8",
   "metadata": {},
   "source": [
    "# Acknowledgements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc21feef",
   "metadata": {},
   "source": [
    "These are the resources which I have found helpful:\n",
    "\n",
    "\n",
    "[BERT (HuggingFace/SentenceTransformers)](https://huggingface.co/sentence-transformers/paraphrase-MiniLM-L6-v2)\n",
    "<br>\n",
    "[Gensim's Word2Vec Implementation](https://www.analyticsvidhya.com/blog/2020/08/top-4-sentence-embedding-techniques-using-python/)\n",
    "<br>\n",
    "[Building Recommender Systems](https://medium.com/analytics-vidhya/movie-recommender-system-using-content-based-and-collaborative-filtering-84a98b9bd98e)\n",
    "<br>\n",
    "[Building Recommender Systems](https://towardsdatascience.com/build-a-text-recommendation-system-with-python-e8b95d9f251c)\n",
    "<br>\n",
    "\n",
    "Other Reading Materials:\n",
    "<br>\n",
    "https://www.jeremyjordan.me/autoencoders/\n",
    "<br>\n",
    "https://neptune.ai/blog/bert-and-the-transformer-architecture-reshaping-the-ai-landscape\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "218px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
